<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://www.thomaslevine.com/</id>
  <title>Thomas Levine</title>
  <updated>2013-09-12T04:00:00Z</updated>
  <link rel="alternate" href="http://www.thomaslevine.com/"/>
  <link rel="self" href="http://www.thomaslevine.com/!/feed.xml"/>
  <author>
    <name>Thomas Levine</name>
    <uri>http://www.thomaslevine.com</uri>
  </author>
  <entry>
    <id>tag:www.thomaslevine.com,2013-09-12:/!/statistics-with-doodles-sudoroom/index.html</id>
    <title type="html">Statistics through doodles</title>
    <published>2013-09-12T04:00:00Z</published>
    <updated>2013-09-12T04:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/statistics-with-doodles-sudoroom/index.html"/>
    <content type="html">&lt;style&gt;
  .control {
    height: auto;
    border: none;
  }
  img.control {
    width: 9%;
    max-width: 50px;
    margin: 0;
    margin-right: 1%;
    padding: 0;
  }
  input[type=range].control {
    width: 75%;
    margin: 0;
    height: 40px;
  }
  video {
    margin: 0;
    border: 0;
    padding: 0;
  }
&lt;/style&gt;

&lt;p&gt;A &lt;em&gt;statistic&lt;/em&gt; is a number that describes a lot of other numbers.
By reducing many numbers into one number, we make it easier to
figure out what the numbers mean; we wouldn’t be able to fit all
of the original numbers in our brain.&lt;/p&gt;

&lt;p&gt;People usually explain statistics with symbols, but I like explaining
statistics with drawings, 
&lt;a href="https://sudoroom.org/wiki/Today_I_Learned#July_20:_Statistics_through_doodles:_Geometric_computations_of_fundamental_statistical_concepts"&gt;I doodled about statistics&lt;/a&gt;
one time in &lt;a href="http://sudoroom.org/"&gt;Sudoroom&lt;/a&gt;,
and we took videos of it. Watch them here!&lt;/p&gt;

&lt;div id="videos"&gt;
  &lt;video width="49%" class="back" src="http://bigdada.thomaslevine.com/til-statistics-back.webm"&gt;&lt;/video&gt;
  &lt;video width="49%" class="above" src="http://bigdada.thomaslevine.com/til-statistics-above.webm"&gt;&lt;/video&gt;
&lt;/div&gt;

&lt;div id="controls"&gt;
  &lt;a id="play" href="javascript:play()"&gt;&lt;img class="control" alt="Play" src="play.jpg" /&gt;&lt;/a&gt;
  &lt;a id="pause" href="javascript:pause()"&gt;&lt;img class="control" alt="Pause" src="pause.jpg" /&gt;&lt;/a&gt;
  &lt;input class="control" id="seek" type="range" min="0" max="1" value="0" step="0.01" /&gt;
&lt;/div&gt;
&lt;p style="text-align: right;"&gt;
  &lt;a href="javascript:big()"&gt;Big videos&lt;/a&gt; | 
  &lt;a href="javascript:small()"&gt;Small videos&lt;/a&gt;
&lt;/p&gt;

&lt;script&gt;document.write('&lt;script src="script.js?date=' + (new Date()).getTime() + '"&gt;&lt;' + '/script&gt;')&lt;/script&gt;

&lt;p&gt;The videos gloss over the reasons why we have these statistics,
so I discuss those reasons below.&lt;/p&gt;

&lt;h2 id="geometric-computations"&gt;Geometric computations&lt;/h2&gt;
&lt;p&gt;In the video, I geometrically computed four statistics
about the relationships between different variables.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Covariance&lt;/li&gt;
  &lt;li&gt;Variance&lt;/li&gt;
  &lt;li&gt;Correlation&lt;/li&gt;
  &lt;li&gt;Least-squares regression coefficients&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Each computation is for the simplest version of the statistic.
For those who like big words, that’s the univariate or bivariate
version, and the population statistic rather than the sample statistic.&lt;/p&gt;

&lt;h2 id="why-we-care-about-these-statistics"&gt;Why we care about these statistics&lt;/h2&gt;
&lt;p&gt;The videos show the computations of these statistics, but they
don’t really explain why we use these statistics. So I’ll explain
that here.&lt;/p&gt;

&lt;h3 id="linear-relationships"&gt;Linear relationships&lt;/h3&gt;
&lt;p&gt;A lot of relationships can be seen as linear relationships.
One such relationship is that between a person’s height and weight;
taller people are heavier, and shorter people are lighter.&lt;/p&gt;

&lt;p&gt;A relationship that isn’t very linear might be 
&lt;a href="/!/ridership-rachenitsa"&gt;public transit ridership and time&lt;/a&gt;.
As time progresses, weekly public transit ridership stays the same.
However, it does change a lot within the week, with high ridership
on the weekdays, low ridership on Saturdays and lower ridership on Sundays.&lt;/p&gt;

&lt;p&gt;The example I used in the video is locations where your friends live,
which might form clusters rather than lines.&lt;/p&gt;

&lt;p&gt;The four statistics that the videos discuss are ways of describing the
strength of a relationship, and they only make sense to use with linear
relationships.&lt;/p&gt;

&lt;h3 id="covariance"&gt;Covariance&lt;/h3&gt;
&lt;p&gt;Covariance is a basic measure of how strong the relationship is.
It is just a number that is&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;zero if there is no relationship,&lt;/li&gt;
  &lt;li&gt;really big if the two variables tend to move in the same direction, and&lt;/li&gt;
  &lt;li&gt;really negative if the two variables tend to move in opposite directions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, the covariance between weight and height is a very positive
number, like maybe 9001, because taller people are heavier. This postive
covariance is represented in the video as lots of orange rectangles in
the top-right and bottom-left quadrants.&lt;/p&gt;

&lt;p&gt;&lt;img src="positive-covariance.jpg" alt="Positive covariance" /&gt;&lt;/p&gt;

&lt;p&gt;The covariance between number of times a person has eaten popcorn and her
shoe size is probably around zero, because I doubt that these are very
strongly related. In the video, we see this as orange and blue rectangles
balancing out.&lt;/p&gt;

&lt;p&gt;&lt;img src="zero-covariance.jpg" alt="Zero covariance" /&gt;&lt;/p&gt;

&lt;p&gt;And the covariance between cholesterol level and lifespan is probably
a very negative number, like maybe -1337, because people with more
cholesterol tend to live less long. That’s blue rectangles, with my
doodles’ conventions.&lt;/p&gt;

&lt;p&gt;&lt;img src="negative-covariance.jpg" alt="Negative covariance" /&gt;&lt;/p&gt;

&lt;p&gt;We tend not to use the covariance very directly in practice because
it’s hard to compare covariances directly to each other. The reasons
for this are explained in the video.&lt;/p&gt;

&lt;h3 id="variance"&gt;Variance&lt;/h3&gt;
&lt;p&gt;Variance is a measure of how spread out one variable is. It is a
positive number that gets big when the variables are more spread out.&lt;/p&gt;

&lt;p&gt;Let’s say that two people are cutting wood to build a house. They cut
10 pieces of wood each, and each piece of wood is supposed to be exactly
120 inches long.&lt;/p&gt;

&lt;p&gt;One person is very careful when he measures the wood, so his pieces come
out perfectly. They’re not exactly 120 inches long because that’s impossible,
but they’re not spot-on for the purposes of construction. The variance of the
lengths of his pieces of wood is very close to zero, like maybe 3.&lt;/p&gt;

&lt;p&gt;The other person is drunk and stoned and thus not very careful, so the
lengths of his pieces are all over the place. They’re still around 10
feet long on average, but some of them are 8 feet long, and others are
11 feet long. The variance of the lengths of this person’s pieces is
very high; maybe it’s 300.&lt;/p&gt;

&lt;p&gt;We talk about variances a lot when we are estimating the average of a
variable. When we estimate an average, we want to know how precise our
estimate is, and the variance tells us that.&lt;/p&gt;

&lt;h3 id="correlation"&gt;Correlation&lt;/h3&gt;
&lt;p&gt;Think of the correlation as a standardized version of the covariance.
The correlation is a number between -1 and 1. Like for the covariance,
positive correlations mean that the variables move together, and negative
correlations mean that the variables move oppositely.&lt;/p&gt;

&lt;p&gt;Like the covariance, the correlation tells us how strongly two variables
are related. The practical difference is that we can compare different
covariances to each other.&lt;/p&gt;

&lt;p&gt;We can compute the correlation between two variables based on the covariance
between the two variables and the respective variances of the two variables.&lt;/p&gt;

&lt;h3 id="least-squares-regression"&gt;Least-squares regression&lt;/h3&gt;
&lt;p&gt;Maybe you want to be able to guess someone’s height based on her weight.
Regression is one way of doing this.&lt;/p&gt;

&lt;p&gt;To predict height from weight, we can use a simple regression that would
tell us two statistics (numbers). In order to calculate these numbers, we
first need to measure the heights and weights of a bunch of people.&lt;/p&gt;

&lt;p&gt;Once we calculate these two numbers, we have a formula for predicting height;
you give the formula a weight, and it will give you back a predicted height.&lt;/p&gt;

&lt;p&gt;The formula is a best-fit line, as shown in this image &lt;a href="http://en.wikipedia.org/wiki/File:Linear_regression.svg"&gt;from Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="regression.png" alt="Regression" /&gt;&lt;/p&gt;

&lt;p&gt;Let’s say we want to know
&lt;a href="http://en.wikipedia.org/wiki/Gas_laws#Charles.27s_law"&gt;how big a balloon gets depending on the temperature of the air&lt;/a&gt;.
We fill a bunch of balloons with air and put them in different places,
each with a different air temperature. In the plot above, each dot would
be a balloon, the numbers along the x-axis (the bottom) would be the
temperature, and the numbers along the y-axis would be the volume of the
balloon. That is the data we started with.&lt;/p&gt;

&lt;p&gt;Using these data, we calculate those two regression statistics I mentioned
above. With these, we can draw the red regression line.&lt;/p&gt;

&lt;p&gt;When we want to predict what the volume of a balloon will be at a particular temperature,
we find the temperature on the x-axis, follow it vertically up to the red line,
then follow it horizontally to the y-axis. This is our predicted volume.&lt;/p&gt;

&lt;h2 id="why-statistics-and-math-and-doodles"&gt;Why statistics and math and doodles&lt;/h2&gt;
&lt;p&gt;Statistics lets us distill our complex observations of the world into simple
numbers that are easier to understand. Covariance, variance, correlation
and least-squares regression are some statistics that are commonly used. The
text explains why we use them, and the video explains how we calculate them.&lt;/p&gt;

&lt;p&gt;The formulae for these statistics get a bit confusing when you write them
out as symbols, but math can always be drawn, and it usually makes more sense
that way.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2013-09-10:/!/street-sign-protocol/index.html</id>
    <title type="html">The Street Sign Protocol</title>
    <published>2013-09-10T04:00:00Z</published>
    <updated>2013-09-10T04:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/street-sign-protocol/index.html"/>
    <content type="html">&lt;p&gt;There are a lot of acronyms on the internet that end in “P”,
like TCP, IP, and HTTP. This “P” stands for “protocol”.
Perhaps you are wondering what a protocol is.&lt;/p&gt;

&lt;p&gt;“Protocol” is one of those words that sounds more special than it really is.
The concept of a computer protocol might sound quite complex, but
it’s a rather generic concept that is something like a language,
an expectation, and a social norm.&lt;/p&gt;

&lt;p&gt;The way a particular protocol works might be quite complicated, but
I just want to explain the generic concept of a protocol. I’m going
to do this by writing about a protocol that you might not think of
as a protocol.&lt;/p&gt;

&lt;h2 id="the-street-sign-protocol"&gt;The street sign protocol&lt;/h2&gt;
&lt;p&gt;I’m going to document a protocol that we might not usually think of a
protocol. Let’s call it the Street Sign Protocol (SSP).&lt;/p&gt;

&lt;p&gt;&lt;img src="street-signs.jpg" alt="Street signs" /&gt;
&lt;!-- http://farm3.staticflickr.com/2132/2302062601_dd0f89779d.jpg
     http://oaklandwiki.org/Street_Signs --&gt;&lt;/p&gt;

&lt;p&gt;To keep things simple, I’ll actually document a simple version of the
Street Sign Protocol. Let’s call it the Simple Street Sign Protocol (SSSP).&lt;/p&gt;

&lt;h3 id="why-we-might-want-sssp"&gt;Why we might want SSSP&lt;/h3&gt;
&lt;p&gt;You might already be familiar with how street signs work, but it took you a while
to figure it out. Also, you are probably so familiar with street signs that you
don’t really think about all of the small details that are involved in communication
through street signs.&lt;/p&gt;

&lt;p&gt;If we wanted to tell a robot how to communicate through street signs, it would be
helpful to be very explicit and precise about all of the aspects of street signs.&lt;/p&gt;

&lt;h3 id="specification"&gt;Specification&lt;/h3&gt;
&lt;p&gt;SSSP is a way of exchanging the names of &lt;em&gt;streets&lt;/em&gt;. It involves
&lt;em&gt;street signs&lt;/em&gt; mounted on &lt;em&gt;poles&lt;/em&gt; near the &lt;em&gt;corners&lt;/em&gt; of
&lt;em&gt;four-way intersections&lt;/em&gt;. Let’s define these terms.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;em&gt;street&lt;/em&gt; is a paved public thoroughfare in a built environment.
  (This definition is taken from &lt;a href="http://en.wikipedia.org/wiki/Street"&gt;Wikipedia&lt;/a&gt;.)&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;four-way intersection&lt;/em&gt; is a place where two streets cross.
  Its shape is approximately a rectangle, with one side having the
  width of one street and the other side having the width of the
  other street.&lt;/li&gt;
  &lt;li&gt;Being rectangular, a four-way intersection has four &lt;em&gt;corners&lt;/em&gt; at the
  usual places.&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;pole&lt;/em&gt; is a long cylinder sticking out of the ground.&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;street sign&lt;/em&gt; is a flat rectangular thing that has text on both faces.
  The sign is oriented such that the text reads left-to-right.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now we can define the SSSP in outrageous precision and verbosity! &lt;em&gt;You’ll probably
get confused as you read the paragraphs below, so keep in mind that this is just
a very precise and verbose explanation of what we usually consider to be street signs&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Each four-way intersection has four corners, and each pole is associated with
a corner of an intersection. Each corner must have zero or one poles, and at least
one of the corners of a four-way intersection must have a pole; thus, an
intersection must have between one and four poles.&lt;/p&gt;

&lt;p&gt;Poles must be mounted within about ten feet of a corner of the intersection
but not on the paved area of the street or the intersection. (It is okay for them
to be mounted on the sidewalk.) It must stick straight out of the ground; the long
axis of the cylinder must be approximately in line with the direction of gravity.&lt;/p&gt;

&lt;p&gt;Each street sign displays the name of one street. The street sign must include the
name of the street in very large text. This name must be written on both faces of
the sign and must be especially easy to see, even at night.&lt;/p&gt;

&lt;p&gt;Street signs are mounted on poles, each pole having exactly two street signs.
The street signs must be aligned in a particular way. One of the faces must be
just-barely-touching (tangent) the pole. The sign must also line up with its
corresponding street; that is, the wide axis of the rectangular sign must run
parallel the corresponding street.&lt;/p&gt;

&lt;p&gt;Each pole must contain two street signs, each one corresponding to a different
one of the two streets at the four-way intersection.&lt;/p&gt;

&lt;h3 id="implementing-a-sssp-writer"&gt;Implementing a SSSP writer&lt;/h3&gt;
&lt;p&gt;Here is one possible procedure for encoding street names in SSSP. This procedure
expects a four-way intersection and the names of the two streets as input. It
outputs SSSP (two street signs mounted to a pole near the intersection).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Determine which corner(s) of the intersections the street signs should be
 mounted on. You might consider the locations of buildings, the presence
 of sidewalks, the traffic patterns and the presence of visual obstacles
 like trees.&lt;/li&gt;
  &lt;li&gt;Print the signs with the street names.&lt;/li&gt;
  &lt;li&gt;Cast a pole.&lt;/li&gt;
  &lt;li&gt;Put a pole and street signs on a truck.&lt;/li&gt;
  &lt;li&gt;Drive the truck to the intersection, and park nearby.&lt;/li&gt;
  &lt;li&gt;Carry the materials and some tools to the intersection.&lt;/li&gt;
  &lt;li&gt;Stick the pole in the ground near the chosen corner. I imagine that this
 involves putting up caution tape, digging a hole, securing the pole, pouring
 some concrete and covering it back up, but I don’t really know. If this were
 software, I’d try to use separate pole-installation library so I don’t have
 to implement the pole-installation procedure myself.&lt;/li&gt;
  &lt;li&gt;Mount the street signs to the pole. Position them about ten feet above the ground,
 with one on top of the other and with the centers of the signs touching the pole,
 and otherwise in the appropriate orientations specified by the protocol. Secure
 them with a sign bracket.&lt;/li&gt;
  &lt;li&gt;Drive the truck back to wherever you got it from.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="implementing-a-sssp-reader"&gt;Implementing a SSSP reader&lt;/h3&gt;
&lt;p&gt;Here is a procedure for decoding SSSP. It has the opposite inputs and outputs as
the SSSP writer.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Look for poles with street signs at the four corners of the four-way intersection.&lt;/li&gt;
  &lt;li&gt;Focus on the first valid pole that you see; ignore any others.&lt;/li&gt;
  &lt;li&gt;Do the following for each of the two street signs.&lt;/li&gt;
  &lt;li&gt;Read the large text on the sign.&lt;/li&gt;
  &lt;li&gt;Associate this large text with the street that the sign lines up with.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id="hypertext-transfer-protocol"&gt;Hypertext Transfer Protocol&lt;/h2&gt;
&lt;p&gt;Now let’s talk about something that people actually call a protocol.
Here’s a simplified version of the Hypertext Transfer Protocol (HTTP).&lt;/p&gt;

&lt;h3 id="why-we-use-http"&gt;Why we use HTTP&lt;/h3&gt;
&lt;p&gt;When you look at stuff on the internet with a web browser, your web browser and
various web servers are sending messages between each other. HTTP is a common
language that all of these computers use.&lt;/p&gt;

&lt;p&gt;While all of these web servers are expecting HTTP, you can actually send them
anything you want. If it is sort of like HTTP but with a few typos, the web
server might figure out what you meant. But if you sent random garbage, the
web server would not have any idea of what you wanted.&lt;/p&gt;

&lt;p&gt;We have common internet languages for the same reasons that we have common
human languages. If you talk to me in English, I’ll understand you quite well.
I’ll make sense of it even you you are not using Queen’s English. But I won’t
really have any idea what you mean if you use sign language.&lt;/p&gt;

&lt;p&gt;We agree to use HTTP on all of these different computers because it makes it
easier for the computers to understand each other.&lt;/p&gt;

&lt;h3 id="highly-simplified-specification"&gt;Highly simplified specification&lt;/h3&gt;
&lt;p&gt;HTTP is a way of exchanging information between a web browser and a web server.
It involves &lt;em&gt;messages&lt;/em&gt;, which are very long series of words, punctuation and
spaces. HTTP prescribes who sends and receives these messages and how these
messages are formatted.&lt;/p&gt;

&lt;p&gt;Some messages have a &lt;em&gt;body&lt;/em&gt;. This is an embedded series of words, punctuation
and spaces that can be written in any format you want.&lt;/p&gt;

&lt;p&gt;Each message may have a bunch of &lt;em&gt;headers&lt;/em&gt;. Each header has a name and a value.
There are a bunch of headers that provide some information about the body
(like its size or format), and there are a bunch of headers that provide
information about the system that is sending the message. And there are others,
like the date of the message.&lt;/p&gt;

&lt;p&gt;Each message is either a request or a response. By being a request, a message
indicates that it came from a web browser and is being sent to a web server.
By being a response, a message indicates that it came from a web server and
is being sent to a web browser. Each response sent from a particular server
to a particular browser must be initiated by a request sent from the
particular browser to particular server.&lt;/p&gt;

&lt;p&gt;Every response has a body (explained above) and a status code. The status code
is a number that explains whether the request succeeded and any quirks about its
success or failure. For example, status code &lt;code&gt;200&lt;/code&gt; means that the request worked
as expected, and status code &lt;code&gt;403&lt;/code&gt; means that you don’t have permission to do
whatever you tried to do.&lt;/p&gt;

&lt;p&gt;Each request must have a method. There are a bunch of methods, and you can think
of them as different commands. Here are a few of them.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;POST&lt;/code&gt; is the method that asks the server to save a new document.
  It contains a body.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;PUT&lt;/code&gt; is the method that asks the server to edit an existing document.
  It contains a body.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;GET&lt;/code&gt; is the method that asks the server to send an existing document in the
  body of the response (and not to alter it). The request does not contain a body.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;HEAD&lt;/code&gt; is the method that asks the server to do everything that it would do in
  for an equivalent &lt;code&gt;GET&lt;/code&gt; request except for sending the body. Like the &lt;code&gt;GET&lt;/code&gt;
  request, the &lt;code&gt;HEAD&lt;/code&gt; request contains no body.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="receiving-and-reading-and-writing-and-sending"&gt;Receiving and reading and writing and sending&lt;/h3&gt;
&lt;p&gt;A bunch of things in your web browser might initiate a request. For example, opening
a web page makes one request, and loading an image on the web page makes another request.&lt;/p&gt;

&lt;p&gt;A computer somewhere (Call it the “web server”.) is running a particular piece of software
(Call it the “HTTP server”.) that is able to receive this request.
The HTTP server receives the request, checks that it is valid, and breaks it into the
method, headers, and body.&lt;/p&gt;

&lt;p&gt;Then the HTTP server asks something else to decide what to do.
After doing everything, this other thing decides what the outcome was and tells the HTTP server.&lt;/p&gt;

&lt;p&gt;The HTTP server composes an HTTP response and
sends that back to the browser.&lt;/p&gt;

&lt;p&gt;The browser breaks that into its various parts and accordingly displays a web page,
shows an image or does whatever else was specified.&lt;/p&gt;

&lt;h2 id="a-protocol-is-an-expectation"&gt;A protocol is an expectation&lt;/h2&gt;
&lt;p&gt;“Protocol” means the same thing for computers as it does for people.
There are lots of different protocols, and some of them are very complicated,
but the word “protocol” itself has a rather simple meaning; it’s just
a way that we expect things to work.&lt;/p&gt;

&lt;p&gt;Like how we agree to speak the same language (probably English if you’re reading this)
or to drive on the same side of the street, we agree on a computer protocol because that
makes it easier for us to make computers communicate. We can choose to build computers
that don’t follow standard protocols, but that would make them hard to understand.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2013-09-03:/!/socrata-formats/index.html</id>
    <title type="html">What file formats are on the data portals?</title>
    <published>2013-09-03T04:00:00Z</published>
    <updated>2013-09-03T04:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/socrata-formats/index.html"/>
    <content type="html">&lt;style&gt;
table {
  font-size: 0.7em;
}
&lt;/style&gt;

&lt;p&gt;I found some more open data about open data to &lt;a href="/socrata"&gt;study&lt;/a&gt;!
While &lt;a href="http://www.socrata.com/blog/my-visit-to-socrata-and-data-analysis-about-data-analysis/"&gt;at Socrata’s office&lt;/a&gt; on Friday,
I learned of the &lt;a href="https://data.oregon.gov/data.json"&gt;&lt;code&gt;/data.json&lt;/code&gt;&lt;/a&gt; endpoint.
It contains an entry for each &lt;a href="/!/socrata-genealogies/#term-dataset"&gt;dataset&lt;/a&gt;,
uploaded by the data publisher; it doesn’t contain all of the other
views that are based on these source datasets.
And it has &lt;a href="http://project-open-data.github.io/schema/"&gt;this format&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id="how-many-datasets"&gt;How many datasets?&lt;/h2&gt;
&lt;p&gt;Socrata portals have &lt;a href="/!/socrata-users/#the-user-data-format"&gt;50,000 different views&lt;/a&gt;, but only
8922 are original datasets.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;/data.json&lt;/code&gt; files include federated datasets, so some of these
datasets are duplicated. I did not remove duplicates, so I’m working
with 15699 datasets, with a median of
96 datasets per portal.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/portal-counts.png"&gt;&lt;img src="figure/portal-counts.png" alt="Datasets per portal, based on the /data.json file" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="no-derived-datasets"&gt;No derived datasets&lt;/h3&gt;
&lt;p&gt;This is much lower than my &lt;a href="/!/socrata-summary"&gt;earlier figure&lt;/a&gt;
because the present figure does not include &lt;a href="/!/socrata-genealogies#soda-queries-filtered-views-charts-maps"&gt;derived views&lt;/a&gt; (map, charts, &amp;amp;c.).&lt;/p&gt;

&lt;p&gt;Some time, I’ll compare the within-portal counts of original datasets
and derived datasets. But not right now.&lt;/p&gt;

&lt;h3 id="federated-data"&gt;Federated data&lt;/h3&gt;
&lt;p&gt;It still includes &lt;a href="/!/socrata-genealogies/#term-federation"&gt;federated data&lt;/a&gt; (duplicates),
however, and this file doesn’t make it easy to determine which direction
the federation is in. The following plot gives us an idea of how many of
these datasets are duplicates.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/federation.png"&gt;&lt;img src="figure/federation.png" alt="The scale of data federation within this subset of Socrata datasets" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of the datasets are not duplicates, but some are duplicated many times.&lt;/p&gt;

&lt;p&gt;Some day, I’ll look more at federation, probably by 
reading the federation information from home pages of the portals
or by following the links in the &lt;code&gt;/data.json&lt;/code&gt; file.&lt;/p&gt;

&lt;h3 id="cutoff-at-1000"&gt;Cutoff at 1000?&lt;/h3&gt;
&lt;p&gt;I find it highly suspicious the following nine portals have exactly 1000
datasets and no portals have more than 1000 datasets.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;paste(names(sort(table(datasets$portal), decreasing = T)[1:9]), collapse = "\n")
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://bronx.lehman.cuny.edu"&gt;bronx.lehman.cuny.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.cityofnewyork.us"&gt;data.cityofnewyork.us&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.hawaii.gov"&gt;data.hawaii.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.illinois.gov"&gt;data.illinois.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.ny.gov"&gt;data.ny.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.ok.gov"&gt;data.ok.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.oregon.gov"&gt;data.oregon.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://explore.data.gov"&gt;explore.data.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.metrochicagodata.org"&gt;www.metrochicagodata.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Half of these portals federate &lt;code&gt;explore.data.gov&lt;/code&gt;, which has quite a few datasets, and the JSON
files seem to just include some of the &lt;code&gt;explore.data.gov&lt;/code&gt; data. I think these
files have only the first 1000 datasets, and I haven’t figured out how to look
at the next pages, so I’ll focus the present analysis on portals with fewer
than 1000 datasets.&lt;/p&gt;

&lt;h2 id="my-curiousity-about-file-formats"&gt;My curiousity about file formats&lt;/h2&gt;
&lt;p&gt;I’ve recently become curious about what formats the datasets come from. When
tabular data get loaded into a Socrata data portal, they get converted to a
tabular representation within the portal software. From that, they get converted
to a range of different tabular formats.&lt;/p&gt;

&lt;p&gt;The Socrata data portal doesn’t explicitly store the source format because of
how the import process works. Most of the data &lt;a href="http://blog.scraperwiki.com/2012/07/31/do-all-analysts-use-excel/"&gt;probably come from Excel&lt;/a&gt;,
and the data that aren’t from Excel typically come from inside of a government
network where policies would make it inconvenient to expose the database to the
world. Because of this, Socrata doesn’t query database servers. Instead, data
publishers write middlemen that act as both database clients and Socrata clients.
They query the database and then make &lt;a href="http://dev.socrata.com/publishers/getting-started"&gt;web requests&lt;/a&gt;
to the Socrata portal.&lt;/p&gt;

&lt;h2 id="datajson-contains-file-format-information"&gt;&lt;code&gt;/data.json&lt;/code&gt; contains file format information&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;/data.json&lt;/code&gt; endpoint contains a file format field per the Project Open Data
schema. This refers to the format of the data as served from the Socrata portal,
not the format it was stored in before it got to the Socrata portal. But this
still tells us something about the source file formats.&lt;/p&gt;

&lt;p&gt;People sometimes upload things that Socrata doesn’t interpret as tables. PDFs are
a major example. Other times, people upload or link to
files that could be tables but don’t specify that they are tables; those are called
“external links”. Read more on dataset types &lt;a href="/!/open-by-default#types-of-visualizations-on-socrata-portals"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Data formats are represented in two fields, &lt;code&gt;format&lt;/code&gt; and &lt;code&gt;distribution&lt;/code&gt;. &lt;code&gt;distribution&lt;/code&gt;{#distribution}
seems to contain all of the different available formats. If the data are imported as
tabular data, it contains CSV, JSON, XML, &amp;amp;c., all served from the Socrata site.
And if the data are external links, it will contain a few external links, still
specifying the file types. The &lt;code&gt;format&lt;/code&gt; field contains one of the formats that are
specified in the &lt;code&gt;distribution&lt;/code&gt; field. I think it’s just the first of the formats.
For the present analysis, I’m using the &lt;code&gt;format&lt;/code&gt; field.&lt;/p&gt;

&lt;p&gt;Recall that the present dataset of datasets counts federated datasets multiple times.
The following plot shows the file types of the deduplicated dataset dataset, across
all portals.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/deduplicated.png"&gt;&lt;img src="figure/deduplicated.png" alt="Formats of datasets across all portals" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And here are some of the main types by portal, counting federated datasets in all of their portals.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/all-formats.png"&gt;&lt;img src="figure/all-formats.png" alt="Data formats on all the portals" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;csv&lt;/code&gt; mostly refers
to data that Socrata represents as a table; this is the sort of data that Socrata
can convert to a range of different tabular data formats.
It is also my &lt;a href="http://csvsoundsystem.com"&gt;preferred file format&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Everything that is not CSV appears to be an external link.&lt;/p&gt;

&lt;h2 id="csv"&gt;CSV&lt;/h2&gt;
&lt;p&gt;Most datasets are CSV (8143 of 15699).
I was curious as to how this varies by portal and over time, and the following image
addresses that.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/csv-cum-facet.png"&gt;&lt;img src="figure/csv-cum-facet.png" alt="Dataset formats by portal over time" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The image above contains one plot per data portal. The x-axis of each plot is the date,
the y-axis is the proportion&lt;sup id="fnref:proportion"&gt;&lt;a href="#fn:proportion" class="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; of datasets that are tabular (CSV), and the
width of the line is the number of datasets on the portal.
For example, if there were 100 datasets on a portal in June 2011 and 80 were CSV, the
line would be near the top of the graph and quite skinny at June 2011.&lt;/p&gt;

&lt;p&gt;We can thus see how many datasets each portal has and what the different formats are.&lt;/p&gt;

&lt;h2 id="some-interesting-portals"&gt;Some interesting portals&lt;/h2&gt;
&lt;p&gt;Some portals have only CSV data (like &lt;code&gt;data.medicare.gov&lt;/code&gt;), but most contain
other data. I am curious both as to what other data formats they have and what
prompted the shifts in dataset format.&lt;/p&gt;

&lt;p&gt;Missouri mostly has PDFs.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/mo.png"&gt;&lt;img src="figure/mo.png" alt="Data formats on data.mo.gov" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also interesting about Missouri is that it federates &lt;a href="https://data.kcmo.org/"&gt;Kansas City&lt;/a&gt;,
which didn’t appear in my list of portals.&lt;/p&gt;

&lt;p&gt;I know I said I’d focus on portals with fewer than 1000 datasets, but Lehman College is
interesting because it has lots of zipped files.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/lehman.png"&gt;&lt;img src="figure/lehman.png" alt="Data formats on bronx.lehman.cuny.edu" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;San Francisco has a lot of CSVs, a lot of externally linked zip files,
and a lot of externally linked files of unknown format.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/sf.png"&gt;&lt;img src="figure/sf.png" alt="Data formats on data.sfgov.org" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="determination-of-external-link-file-formats"&gt;Determination of external link file formats&lt;/h2&gt;
&lt;p&gt;It looks like the format of external links is determined by the file name.
For example, Edmonton’s
&lt;a href="https://data.edmonton.ca/Transportation/Road-and-Traffic-Updates/5ggc-prfp?"&gt;Road and Traffic Updates&lt;/a&gt;
are marked as &lt;code&gt;application/rss+xml&lt;/code&gt; because the external link,
&lt;a href="http://www.trumba.com/calendars/construction-and-special-events-road-closures.rss"&gt;http://www.trumba.com/calendars/construction-and-special-events-road-closures.rss&lt;/a&gt;,
ends in &lt;code&gt;.rss&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In contrast, the &lt;a href="https://data.maryland.gov/d/ywbg-ptfh"&gt;Maryland Land Use/ Land Cover: 1973, 2002, 2010&lt;/a&gt;
dataset is marked as having the format &lt;code&gt;application/octet-stream&lt;/code&gt; because the
external link, &lt;a href="http://planning.maryland.gov/OurWork/landUseDownload.shtml"&gt;http://planning.maryland.gov/OurWork/landUseDownload.shtml&lt;/a&gt;,
ends in &lt;code&gt;.shtml&lt;/code&gt;.&lt;/p&gt;

&lt;!-- sqldf("select title, 'https://' || portal || '/d/' || identifier AS portalURL, accessURL from catalog where identifier = 'ywbg-ptfh'", dbname = '/tmp/catalog.db') --&gt;

&lt;h2 id="dates-of-significant-changes"&gt;Dates of significant changes&lt;/h2&gt;
&lt;p&gt;A few portals have only CSV data since the beginning, but most have had other formats.
Looking at the plots, we can see dates where there was a sudden change in the proportion
of datasets that were CSV.&lt;/p&gt;

&lt;h3 id="sudden-changes-at-the-beginning"&gt;Sudden changes at the beginning&lt;/h3&gt;
&lt;p&gt;When the first dataset gets uploaded, the proportion of datasets that are CSV is either
zero or one. Thus, the line for all of these datasets starts either at zero or one.
Most datasets sharply change after that; &lt;code&gt;data.austintexas.gov&lt;/code&gt; and &lt;code&gt;data.mo.gov&lt;/code&gt; are
examples.&lt;/p&gt;

&lt;p&gt;Others stay at this level for quite a while because no datasets were uploaded for a
while. &lt;code&gt;data.raleighnc.gov&lt;/code&gt; is an example of this. Here are its first ten datasets.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;created&lt;/th&gt;
      &lt;th&gt;format&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/s68n-gffw"&gt;Building Permit Data&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-03-14&lt;/td&gt;
      &lt;td&gt;text/csv&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/pep8-sb8v"&gt;Building Permit Data&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-03-14&lt;/td&gt;
      &lt;td&gt;text/csv&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/fuys-kh3c"&gt;City of Raleigh Quickfacts&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-19&lt;/td&gt;
      &lt;td&gt;text/csv&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/g3uq-k7zm"&gt;Raleigh Parking&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/jrpi-4amz"&gt;Raleigh Electric Utilities 2011&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/fcx2-d4t3"&gt;Raleigh Communications 2011&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/46tk-23jt"&gt;Raleigh Buildings 2011&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/3fmi-wyx6"&gt;Raleigh Parks and Trails&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/pwv5-a5ca"&gt;Raleigh Trail Areas&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/apbx-xr7f"&gt;Family Income In The Past 12 Months&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;text/csv&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The first two datasets were uploaded in the middle of March 2012 and were CSV format,
making the datasets 100% CSV. The next was uploaded in the middle of February 2013 and
was also CSV, so the proportion was still 100% CSV. At the end of the month, six
zip files were uploaded, reducing the proportion to 33% CSV.&lt;/p&gt;

&lt;h3 id="sudden-changes-after-the-beginning"&gt;Sudden changes after the beginning&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;data.sfgov.org&lt;/code&gt; had a sudden change in the proportion of datasets that were CSV, but
it was after a long while, so a lot of related datasets might have been uploaded all
at once. Let’s look at when datasets were uploaded.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/sf-changes.png"&gt;&lt;img src="figure/sf-changes.png" alt="Formats of newly open San Francisco datasets over time" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This has the quite similar information to the earlier plots, but it’s a bit more precise.
San Francisco added lots of datasets in January 2012, November 2012, and December 2012, and proportionately
few of these datasets were CSV. What were they?&lt;/p&gt;

&lt;p&gt;Here are ten of the January datasets.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;created&lt;/th&gt;
      &lt;th&gt;format&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/2ivi-ywmk"&gt;Arterial Streets of San Francisco (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/2xc9-is4u"&gt;Orthophoto 1ft resolution (1993) - (Zipped MrSID Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/3vyz-qy9p"&gt;City Lots (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/4aaa-ycik"&gt;Census 2000 Block Group (No Water) (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/4drs-6tjy"&gt;Orthophoto 1ft (1993) - Treasure Island (Zipped MrSID Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/4mzs-yjt7"&gt;SFPD Sectors&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/5aii-qc4e"&gt;SFPD Crime Reporting Plots (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/5fxg-wene"&gt;Neighborhood Marketplace Initiative Corridors (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/5rn4-fswj"&gt;San Francisco Basemap Street Centerlines (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/5sny-6aph"&gt;The Presidio of San Francisco (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;It looks like January is mostly externally linked, zipped shapefiles. Most of the
datasets say “shapefile” in their &lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; or &lt;a href="#distribution"&gt;&lt;code&gt;distribution&lt;/code&gt;&lt;/a&gt; fields.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/sf-shapefile.png"&gt;&lt;img src="figure/sf-shapefile.png" alt="Formats of newly open San Francisco datasets over time" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And a lot of the rest of the January files look like zipped shapefiles, even though the
titles and descriptions don’t say so.&lt;/p&gt;

&lt;p&gt;So San Francisco suddenly uploaded a bunch of shapefiles in January and November/December.&lt;/p&gt;

&lt;h3 id="plateaus-of-dataset-counts"&gt;Plateaus of dataset counts&lt;/h3&gt;
&lt;p&gt;Some of the plots make it look like lots of datasets were suddenly uploaded one time
and no datasets were uploaded again. This is mainly for the
&lt;a href="#cutoff-at-1000"&gt;portals with more than 1000 datasets&lt;/a&gt;,
so I think this is because we’re seeing only the first 1000 datasets.&lt;/p&gt;

&lt;h2 id="csv-pdf-zip-and-octet-stream"&gt;CSV, pdf, zip and octet-stream&lt;/h2&gt;
&lt;p&gt;Based on the examples above, it seems like a lot of datasets are PDF, zip or unknown
external links. I made the following series of plots to check it. It is just like the
&lt;a href="#csv"&gt;similar image above&lt;/a&gt; except for the y-axes; instead of representing the
proportion of datasets that are CSV, each y-axis represents the proportion of datasets
that are CSV, PDF, zip or unknown external links.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/csv-pdf-zip-octet-cum-facet.png"&gt;&lt;img src="figure/csv-pdf-zip-octet-cum-facet.png" alt="Dataset formats by portal over time" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of the curves are pretty straight and stay near 1, meaning that the proportion doesn’t
change much and that the proportion is quite high. Thus, it looks like most datasets are
either CSV, pdf, zip or external links of unknown format.&lt;/p&gt;

&lt;h2 id="conclusions"&gt;Conclusions&lt;/h2&gt;

&lt;h3 id="formats"&gt;Formats&lt;/h3&gt;
&lt;p&gt;I was mainly wondering about the source formats of the data. It turns out that most datasets
are tables. Aside from tables, there are lots of externally linked files, mostly PDFs and zip archives.&lt;/p&gt;

&lt;h3 id="shapefiles"&gt;Shapefiles&lt;/h3&gt;
&lt;p&gt;I’ve been thinking recently about how to infer the organizational structure of a municipality
based on the open data that they release, and the finding with the San Francisco shapefiles
alludes to this. It might be that one department within the San Francisco government manages
and uses most of the geospatial data and that the open data team happened to work with them
in January, November and December of 2012.&lt;/p&gt;

&lt;h2 id="future-study"&gt;Future study&lt;/h2&gt;
&lt;p&gt;This got me thinking about other ways of studying file formats.&lt;/p&gt;

&lt;h3 id="the-attribution-field"&gt;The attribution field&lt;/h3&gt;
&lt;p&gt;Socrata’s SODA 1 API, which I’ve &lt;a href="/!/socrata-summary/#download-dataset-metadata"&gt;used before&lt;/a&gt;,
contains an &lt;code&gt;attribution&lt;/code&gt; field, which references the URL from
which the dataset was taken.&lt;sup id="fnref:attribution"&gt;&lt;a href="#fn:attribution" class="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; This would be one
way of figuring out the source format, or at least some related information about the source.&lt;/p&gt;

&lt;h3 id="externally-linked-csvs"&gt;Externally linked CSVs&lt;/h3&gt;
&lt;p&gt;Not all of the CSV-formatted datasets necessarily come from Socrata; some might be links
to external CSV files. There is enough information in &lt;code&gt;/data.json&lt;/code&gt; to determine which of
these categories a CSV dataset falls into.&lt;/p&gt;

&lt;h3 id="determining-the-formats-of-external-links"&gt;Determining the formats of external links&lt;/h3&gt;
&lt;p&gt;It looks to me like the format type of external links is determined based on the file
extension of the URL; &lt;code&gt;octet-stream&lt;/code&gt; datasets seem to correspond to URLs without file
extensions or with file extensions like &lt;code&gt;aspx&lt;/code&gt; that don’t clearly correspond to a
particular file types. One could determine the formats of these datasets by
downloading the files.&lt;/p&gt;

&lt;h2 id="footnotes"&gt;Footnotes&lt;/h2&gt;

&lt;div class="footnotes"&gt;
  &lt;ol&gt;
    &lt;li id="fn:proportion"&gt;
      &lt;p&gt;It’s actually a tad bit more complicated than that. These dates are the
creation dates of the datasets that are available today; I do not know about datasets
that were historically on the portal and have since been deleted.&lt;a href="#fnref:proportion" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id="fn:attribution"&gt;
      &lt;p&gt;I presume that this is entered manually.&lt;a href="#fnref:attribution" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2013-08-21:/!/open-by-default/index.html</id>
    <title type="html">Open by default</title>
    <published>2013-08-21T04:00:00Z</published>
    <updated>2013-08-21T04:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/open-by-default/index.html"/>
    <content type="html">&lt;p&gt;The first of Sunlight Foundation’s 32
&lt;a href="http://sunlightfoundation.com/opendataguidelines/"&gt;Open Data Policy Guidelines&lt;/a&gt;
is to “Set The Default To Open”.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Most public records systems, including the Freedom of Information Act itself, are systems of reactive disclosure – meaning that a question has to be asked before an answer given; public information requested, before it is disclosed.&lt;/p&gt;

  &lt;p&gt;Proactive disclosure is the opposite. Proactive disclosure is the release of public information – online and in open formats (see Provisions 8 and 9) – before it is asked for. This is no simple task, but, in a way, it’s what all “open data” is aiming to accomplish. Setting the default to open means that the government and parties acting on its behalf will make public information available proactively and that they’ll put that information within reach of the public (online), with low to no barriers for its reuse and consumption. Open formats may help us maximize on the value we can extract from certain kinds of public data today, but to ensure that data publishing is sustained and, in fact, made easier over time, we need to reset the default for how data is released and disclosed.&lt;/p&gt;

  &lt;p&gt;Setting the default to open is about living up to the potential of our information, about looking at comprehensive information management, and making determinations that fall in the public interest. It’s about purely practical government improvements, too, and taking steps that not only keep government systems up to date, but ensure that we have the foresight to survive changes in technology that we can’t predict.&lt;/p&gt;

  &lt;p&gt;Usually, for information to be defined as public, important restrictions have already been applied. Therefore, policy language can be used to outline that “all public data and information must be considered open and accessible.” Whether listed as part of a statement of intent (as Austin, Texas does; a concept explored more in Provision 21), as direction to a new oversight authority (Provision 22), or as the underlying aim of new data guidance (Provision 20), openness by default is a critical tool in crafting open data policies that are both ambitious and sustainable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After discovering something on Socrata data portals, I remarked that
software can encourage this practice of making data open by default.&lt;/p&gt;

&lt;h2 id="types-of-visualizations-on-socrata-portals"&gt;Types of visualizations on Socrata portals&lt;/h2&gt;
&lt;p&gt;I previously &lt;a href="/!/socrata-summary"&gt;downloaded&lt;/a&gt; metadata about all of
the datasets on all of the Socrata portals, and I continue to find
interesting things in these data. Let’s look at the different types
of visualizations (“&lt;a href="/!/socrata-genealogies#term-view"&gt;views&lt;/a&gt;”) on the portals.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/not_boring.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;(I excluded tables and external links from the above plot.)&lt;/p&gt;

&lt;p&gt;I was somewhat surprised to see forms and calendars in the portals.
I’ve &lt;a href="/!/open-calendars"&gt;previously&lt;/a&gt; written about why I think Socrata calendars are cool,
so now I’m just going to talk about forms.&lt;/p&gt;

&lt;h3 id="popularity-of-forms"&gt;Popularity of forms&lt;/h3&gt;
&lt;p&gt;Much of the goal of these portals is to open up existing government data, but
&lt;a href="https://data.wa.gov/Economics/Broadband-Project-Data-Entry/38rz-krmg?"&gt;forms&lt;/a&gt; provide a way for citizens to create data.
lets you enter data. A bunch of people have implemented them, but none seems to get accessed much.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/form_use_3.png" alt="Form use by portal" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;I’m gonna remove opendata.socrata.com to make that easier to read.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/form_use_4.png" alt="Form use by portal, excluding opendata.socrata.com" class="wide" /&gt;&lt;/p&gt;

&lt;h3 id="cool-forms"&gt;Cool Forms&lt;/h3&gt;
&lt;p&gt;I hadn’t seen &lt;a href="https://nmfs.socrata.com"&gt;nmfs.socrata.com&lt;/a&gt; before.
It belongs to the &lt;a href="http://www.nmfs.noaa.gov"&gt;National Oceanic and Atmospheric Administration Fisheries Service&lt;/a&gt;,
which apparently used &lt;a href="https://nmfs.socrata.com/Government/2011-Aquaculture-Public-Comments-Form/u5id-8nqp"&gt;a Socrata form&lt;/a&gt; to power a
&lt;a href="http://www.nmfs.noaa.gov/aquaculture/policy2/"&gt;policy comments website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;New York made a form for &lt;a href="https://data.ny.gov/dataset/Give-Feedback/fq3e-q75i?"&gt;feedback on the portal&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;World Bank Open Finances made a
&lt;a href="https://finances.worldbank.org/dataset/Global-Open-Data-Calendar-Entry-Form/qdbh-rfd3?"&gt;form&lt;/a&gt;
that populates an
&lt;a href="https://finances.worldbank.org/dataset/Global-Open-Data-Calendar/g4sx-dwxc"&gt;open data events calendar&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id="relevance-to-software"&gt;Relevance to software&lt;/h2&gt;
&lt;p&gt;The three examples of Socrata forms show us how we can turn user input on a website into
open data automatically. Using a Socrata form to compose a dataset is quite inconvenient,
unreliable, limited, and other bad things, but I see this as a nice example of how software
can encourage that data be open by default. I previously
&lt;a href="http://thomaslevine.com/!/socrata-calendars#opening-data-at-their-sources"&gt;hinted&lt;/a&gt; at this,
but now I have two specific ideas as to how software can encourage that data be open by default.&lt;/p&gt;

&lt;h3 id="standard-formats"&gt;1. Standard formats&lt;/h3&gt;
&lt;p&gt;If you run any sort of involved website, you are probably already storing data in some
reasonably standard way, and you probably could send it to a data portal somewhat easily.&lt;/p&gt;

&lt;h4 id="opening-user-entered-application-data-on-your-websites-database"&gt;Opening user-entered application data on your website’s database&lt;/h4&gt;
&lt;p&gt;One advantage of the Socrata form approach is that the data go automatically into a
reasonably standard format (a Socrata dataset). It happens that most websites work this
way, except that the standard format is something like MySQL.&lt;/p&gt;

&lt;p&gt;A notable difference is that database software generally doesn’t concern itself as
strongly with opening the data. Many websites have HTTP APIs, but few will give out
direct access to their databases. And even if they did this, it wouldn’t provide the
various cataloging and format conversion features that people expect of data portals.
This is why we make data portals that import from these databases and provide all the
fancy features.&lt;/p&gt;

&lt;p&gt;If you have a website that stores information in a standard database (like MySQL) and
you separate the private information from the public information, you already can quite
safely and easily have it sent to a data portal.&lt;/p&gt;

&lt;p&gt;If you are making a new website and care about open data, try to choose a common
database for which integrations will already exist.&lt;/p&gt;

&lt;h4 id="storing-user-entered-application-data-directly-in-a-data-portal"&gt;Storing user-entered application data directly in a data portal&lt;/h4&gt;
&lt;p&gt;If you have a simple website, maybe you don’t have to run your own database
and write your own web APIs. You could store the data directly in the data portal
and query it from the data portal. If this is powerful enough for you, it
simplifies your database management, and it naturally makes your data open by default.&lt;/p&gt;

&lt;h4 id="opening-data-from-some-other-software"&gt;Opening data from some other software&lt;/h4&gt;
&lt;p&gt;Every time you save something in a computer program, you are creating some sort
of data, just like when you fill out a form on an open data portal.
If you have purchased a software service, you might not have access to the
underlying database, but you can still send it to a data portal.&lt;/p&gt;

&lt;p&gt;When a lot of people use services like these, the services’ protocols naturally
become standard, so it becomes worthwhile to write tools that pull data from these
services into some standard place like a data portal. Using a standard service
with lots of users and integrations should make it easier for you to get the data
into a data portal.&lt;/p&gt;

&lt;h3 id="explicit-separation-between-public-and-private-data"&gt;2. Explicit separation between public and private data&lt;/h3&gt;
&lt;p&gt;With a questionnaire, you might be able to just say that all of the responses are
private or that all are public. With other datasets, you might be able to say that
certain fields are private and others are public; in a database of employees, name
and salary can be public, but Social Security number can’t.&lt;/p&gt;

&lt;p&gt;Things aren’t always this simple. With something like project management software,
some records/documents should be private and others should be public. Many of the
entries in project management software are probably safe for public disclosure,
but there might be some private information; for example, I’ve put passwords inside
calendar entries and issue tracker tickets.&lt;/p&gt;

&lt;p&gt;Project management software, email clients, calendars, web browsers and image
editors all contain rich data that can help people understand how government
and other organizations work, so we should find ways of separating the public
information and opening that. Software can help with this.&lt;/p&gt;

&lt;p&gt;Separate public information and private information from the beginning, and it
should be easier to open the data that is behind all of these applications.
The user interface can expose the separation between public and private and
encourage that information public by default.&lt;/p&gt;

&lt;h2 id="things-to-think-about"&gt;Things to think about&lt;/h2&gt;
&lt;p&gt;Think about what programs you and others are already using, especially if you
don’t think of them as data programs, and think about how you can open the data in these programs.
A program’s data will be easy to open if the program already stores its data in
a standard format on the internet and it clearly separates public data from
private data.&lt;/p&gt;

&lt;p&gt;Also think about how we can make software that follows the policy guideline of
open data by default. I’ve proposed that clear separations between public and
private data is part of this and that standard storage methods is another, but
there are surely other relevant features.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2013-08-19:/!/reciprocity/index.html</id>
    <title type="html">Reciprocity</title>
    <published>2013-08-19T04:00:00Z</published>
    <updated>2013-08-19T04:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/reciprocity/index.html"/>
    <content type="html">&lt;p&gt;Last year, while on my way to the &lt;a href="http://www.ire.org/nicar/"&gt;NICAR&lt;/a&gt;
conference, I found myself in Chicago for a couple hours waiting for
a train. This was enough time for me to lunch with a friend who was
working at the University of Chicago.&lt;/p&gt;

&lt;p&gt;I was about to catch a bus towards the university when I realized
that my smallest denomination of currency was a $5 bill. Since the buses
only take exact change, I looked around for a way to break it. I asked a
person who was waiting for the bus with me if she could break it, and she
said she didn’t have change.&lt;/p&gt;

&lt;p&gt;We both wound up getting on the same bus, and I got on first.
I told the bus driver that the $5 was for both of us, and then I promptly
walked to the back of the bus, still a few yards ahead of the other person.&lt;/p&gt;

&lt;p&gt;Shortly after I sat down, this person made her way to the back of the bus,
gave me two dollars and then found an empty seat towards the middle of the bus.&lt;/p&gt;

&lt;p&gt;This person went slightly out of her way to pay me for the bus ride that
I gave her. Reciprocity is cool.&lt;/p&gt;
</content>
  </entry>
</feed>

