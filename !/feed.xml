<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://www.thomaslevine.com/</id>
  <title>Thomas Levine</title>
  <updated>2013-09-08T07:00:00Z</updated>
  <link rel="alternate" href="http://www.thomaslevine.com/"/>
  <link rel="self" href="http://www.thomaslevine.com/!/feed.xml"/>
  <author>
    <name>Thomas Levine</name>
    <uri>http://www.thomaslevine.com</uri>
  </author>
  <entry>
    <id>tag:www.thomaslevine.com,2013-09-08:/!/street-sign-protocol/index.html</id>
    <title type="html">The Street Sign Protocol</title>
    <published>2013-09-08T07:00:00Z</published>
    <updated>2013-09-08T07:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/street-sign-protocol/index.html"/>
    <content type="html">&lt;p&gt;“Protocol” is one of those words that sounds more special than it is.
The concept of a computer protocol might sound quite complex, but
it’s a rather generic concept that is something like a language,
an expectation, and a social norm.&lt;/p&gt;

&lt;p&gt;The way a particular protocol works might be quite complicated, but
I just want to explain the generic concept of a protocol. I’ll explain
this through two example protocols.&lt;/p&gt;

&lt;h2 id="the-street-sign-protocol"&gt;The street sign protocol&lt;/h2&gt;
&lt;p&gt;&lt;img src="street-signs.jpg" alt="Street signs" /&gt;
&lt;!-- http://farm3.staticflickr.com/2132/2302062601_dd0f89779d.jpg
     http://oaklandwiki.org/Street_Signs --&gt;&lt;/p&gt;

&lt;p&gt;First, I’ll document a protocol that we might not usually think of a
protocol. Let’s call it the Street Sign Protocol (SSP).&lt;/p&gt;

&lt;p&gt;To keep things simple, I’ll actually document a simple version of the
Street Sign Protocol. Let’s call it the Simple Street Sign Protocol (SSSP).&lt;/p&gt;

&lt;h3 id="specification"&gt;Specification&lt;/h3&gt;
&lt;p&gt;SSSP is a way of exchanging the names of &lt;em&gt;streets&lt;/em&gt;. It involves
&lt;em&gt;street signs&lt;/em&gt; mounted on &lt;em&gt;poles&lt;/em&gt; near the &lt;em&gt;corners&lt;/em&gt; of
&lt;em&gt;four-way intersections&lt;/em&gt;. Let’s define these terms.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;em&gt;street&lt;/em&gt; is a paved public thoroughfare in a built environment.
  (This definition is taken from &lt;a href="http://en.wikipedia.org/wiki/Street"&gt;Wikipedia&lt;/a&gt;.)&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;four-way intersection&lt;/em&gt; is a place where two streets cross.
  Its shape is approximately a rectangle, with one side having the
  width of one street and the other side having the width of the
  other street.&lt;/li&gt;
  &lt;li&gt;Being rectangular, a four-way intersection has four &lt;em&gt;corners&lt;/em&gt; at the
  usual places.&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;pole&lt;/em&gt; is a long cylinder sticking out of the ground.&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;street sign&lt;/em&gt; is a flat rectangular thing that has text on both faces.
  The sign is oriented such that the text reads left-to-right.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next, let’s discuss what is expected of all of the.&lt;/p&gt;

&lt;p&gt;Each four-way intersection has four corners, and each pole is associated with
a corner of an intersection. Each corner must have zero or one poles, and at least
one of the corners of a four-way intersection must have a pole; thus, an
intersection must have between one and four poles.&lt;/p&gt;

&lt;p&gt;Poles must be mounted within about ten feet of a corner of the intersection
but not on the paved area of the street or the intersection. (It is okay for them
to be mounted on the sidewalk.) It must stick straight out of the ground; the long
axis of the cylinder must be approximately in line with the direction of gravity.&lt;/p&gt;

&lt;p&gt;Each street sign displays the name of one street. The street sign must include the
name of the street in very large text. This name must be written on both faces of
the sign and must be especially easy to see, even at night.&lt;/p&gt;

&lt;p&gt;Street signs are mounted on poles, each pole having exactly two street signs.
The street signs must be aligned in a particular way. One of the faces must be
just-barely-touching (tangent) the pole. The sign must also line up with its
corresponding street; that is, the wide axis of the rectangular sign must run
parallel the corresponding street.&lt;/p&gt;

&lt;p&gt;Each pole must contain two street signs, each one corresponding to a different
one of the two streets at the four-way intersection.&lt;/p&gt;

&lt;h3 id="implementing-a-sssp-writer"&gt;Implementing a SSSP writer&lt;/h3&gt;
&lt;p&gt;Here is one possible procedure for encoding street names in SSSP. This procedure
expects a four-way intersection and the names of the two streets as input. It
outputs SSSP (two street signs mounted to a pole near the intersection).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Determine which corner(s) of the intersections the street signs should be
 mounted on. You might consider the locations of buildings, the presence
 of sidewalks, the traffic patterns and the presence of visual obstacles
 like trees.&lt;/li&gt;
  &lt;li&gt;Print the signs with the street names.&lt;/li&gt;
  &lt;li&gt;Cast a pole.&lt;/li&gt;
  &lt;li&gt;Put a pole and street signs on a truck.&lt;/li&gt;
  &lt;li&gt;Drive the truck to the intersection, and park nearby.&lt;/li&gt;
  &lt;li&gt;Carry the materials and some tools to the intersection.&lt;/li&gt;
  &lt;li&gt;Stick the pole in the ground near the chosen corner. I imagine that this
 involves putting up caution tape, digging a hole, securing the pole, pouring
 some concrete and covering it back up, but I don’t really know. If this were
 software, I’d try to use separate pole-installation library so I don’t have
 to implement the pole-installation procedure myself.&lt;/li&gt;
  &lt;li&gt;Mount the street signs to the pole. Position them about ten feet above the ground,
 with one on top of the other and with the centers of the signs touching the pole,
 and otherwise in the appropriate orientations specified by the protocol. Secure
 them with a sign bracket.&lt;/li&gt;
  &lt;li&gt;Drive the truck back to wherever you got it from.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="implementing-a-sssp-reader"&gt;Implementing a SSSP reader&lt;/h3&gt;
&lt;p&gt;Here is a procedure for decoding SSSP. It has the opposite inputs and outputs as
the SSSP writer.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Look for poles with street signs at the four corners of the four-way intersection.&lt;/li&gt;
  &lt;li&gt;Focus on the first valid pole that you see; ignore any others.&lt;/li&gt;
  &lt;li&gt;Do the following for each of the two street signs.&lt;/li&gt;
  &lt;li&gt;Read the large text on the sign.&lt;/li&gt;
  &lt;li&gt;Associate this large text with the street that the sign lines up with.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id="hypertext-transfer-protocol"&gt;Hypertext Transfer Protocol&lt;/h2&gt;
&lt;p&gt;Now let’s talk about something that people actually call a protocol.
Here’s a simplified version of the Hypertext Transfer Protocol (HTTP)&lt;/p&gt;

&lt;h3 id="highly-simplified-specification"&gt;Highly simplified specification&lt;/h3&gt;
&lt;p&gt;HTTP is a way of exchanging commands between a web browser and a web server.
It is represented as a very long series of words, punctuation and spaces.&lt;/p&gt;

&lt;p&gt;Some messages have a &lt;em&gt;body&lt;/em&gt;. This is an embedded series of words, punctuation
and spaces that can be written in any format you want. (You could use this to
write another protocol on top of HTTP.)&lt;/p&gt;

&lt;p&gt;Each message may have a bunch of &lt;em&gt;headers&lt;/em&gt;. Each header has a name and a value.
There are a bunch of headers that provide some information about the body
(like its size or format), and there are a bunch of headers that provide
information about the system that is sending the message. And there are others,
like the date of the message.&lt;/p&gt;

&lt;p&gt;Each message is either a request or a response. By being a request, a message
indicates that it came from a web browser and is being sent to a web server.
By being a response, a message indicates that it came from a web server and
is being sent to a web browser. Each response sent from a particular server
to a particular browser must be initiated by a request sent from the
particular browser to particular server.&lt;/p&gt;

&lt;p&gt;Every response has a body (explained above) and a status code. The status code
is a number that explains whether the request succeeded and any quirks about its
success or failure. For example, status code &lt;code&gt;200&lt;/code&gt; means that the request worked
as expected, and status code &lt;code&gt;403&lt;/code&gt; means that the web browser is not allowed to
run the command that it requested.&lt;/p&gt;

&lt;p&gt;Each request must have a method. There are a bunch of methods, and you can think
of them as different commands. Here are a few of them.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;POST&lt;/code&gt; is the method that asks the server to save a new document.
  It contains a body.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;PUT&lt;/code&gt; is the method that asks the server to edit an existing document.
  It contains a body.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;GET&lt;/code&gt; is the method that asks the server to send an existing document in the
  body of the response (and not to alter it). The request does not contain a body.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;HEAD&lt;/code&gt; is the method that asks the server to do everything that it would do in
  for an equivalent &lt;code&gt;GET&lt;/code&gt; request except for sending the body. Like the &lt;code&gt;GET&lt;/code&gt;
  request, the &lt;code&gt;HEAD&lt;/code&gt; request contains no body.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="receiving-and-reading-and-writing-and-sending"&gt;Receiving and reading and writing and sending&lt;/h3&gt;
&lt;p&gt;A bunch of things in your web browser might initate a request. For example, opening
a web page makes one request, and loading an image on the web page makes another request.&lt;/p&gt;

&lt;p&gt;The web server receives the request, checks that it is valid, and breaks it into the
component method, headers, and body. Then the web server asks something else to decide
what to do. After doing everything, this other thing decides what the outcome of the
command was and tells the web server. The web server composes an HTTP response and
sends that back to the browser.&lt;/p&gt;

&lt;p&gt;The browser breaks that into its various parts and accordingly displays a web page,
shows an image or does whatever else was specified.&lt;/p&gt;

&lt;h2 id="review"&gt;Review&lt;/h2&gt;
&lt;p&gt;A particular protocol might get quite complicated, but the concept of a protocol
is quite general.
A computer protocol is just a way that we expect things to work, and we agree on a
computer protocol because that makes it easier for us to make computers communicate.
“Protocol” means the same thing for computers as it does for people.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2013-09-03:/!/socrata-formats/index.html</id>
    <title type="html">What file formats are on the data portals?</title>
    <published>2013-09-03T07:00:00Z</published>
    <updated>2013-09-03T07:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/socrata-formats/index.html"/>
    <content type="html">&lt;style&gt;
table {
  font-size: 0.7em;
}
&lt;/style&gt;

&lt;p&gt;I found some more open data about open data to &lt;a href="/socrata"&gt;study&lt;/a&gt;!
While &lt;a href="http://www.socrata.com/blog/my-visit-to-socrata-and-data-analysis-about-data-analysis/"&gt;at Socrata’s office&lt;/a&gt; on Friday,
I learned of the &lt;a href="https://data.oregon.gov/data.json"&gt;&lt;code&gt;/data.json&lt;/code&gt;&lt;/a&gt; endpoint.
It contains an entry for each &lt;a href="/!/socrata-genealogies/#term-dataset"&gt;dataset&lt;/a&gt;,
uploaded by the data publisher; it doesn’t contain all of the other
views that are based on these source datasets.
And it has &lt;a href="http://project-open-data.github.io/schema/"&gt;this format&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id="how-many-datasets"&gt;How many datasets?&lt;/h2&gt;
&lt;p&gt;Socrata portals have &lt;a href="/!/socrata-users/#the-user-data-format"&gt;50,000 different views&lt;/a&gt;, but only
8922 are original datasets.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;/data.json&lt;/code&gt; files include federated datasets, so some of these
datasets are duplicated. I did not remove duplicates, so I’m working
with 15699 datasets, with a median of
96 datasets per portal.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/portal-counts.png"&gt;&lt;img src="figure/portal-counts.png" alt="Datasets per portal, based on the /data.json file" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="no-derived-datasets"&gt;No derived datasets&lt;/h3&gt;
&lt;p&gt;This is much lower than my &lt;a href="/!/socrata-summary"&gt;earlier figure&lt;/a&gt;
because the present figure does not include &lt;a href="/!/socrata-genealogies#soda-queries-filtered-views-charts-maps"&gt;derived views&lt;/a&gt; (map, charts, &amp;amp;c.).&lt;/p&gt;

&lt;p&gt;Some time, I’ll compare the within-portal counts of original datasets
and derived datasets. But not right now.&lt;/p&gt;

&lt;h3 id="federated-data"&gt;Federated data&lt;/h3&gt;
&lt;p&gt;It still includes &lt;a href="/!/socrata-genealogies/#term-federation"&gt;federated data&lt;/a&gt; (duplicates),
however, and this file doesn’t make it easy to determine which direction
the federation is in. The following plot gives us an idea of how many of
these datasets are duplicates.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/federation.png"&gt;&lt;img src="figure/federation.png" alt="The scale of data federation within this subset of Socrata datasets" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of the datasets are not duplicates, but some are duplicated many times.&lt;/p&gt;

&lt;p&gt;Some day, I’ll look more at federation, probably by 
reading the federation information from home pages of the portals
or by following the links in the &lt;code&gt;/data.json&lt;/code&gt; file.&lt;/p&gt;

&lt;h3 id="cutoff-at-1000"&gt;Cutoff at 1000?&lt;/h3&gt;
&lt;p&gt;I find it highly suspicious the following nine portals have exactly 1000
datasets and no portals have more than 1000 datasets.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;paste(names(sort(table(datasets$portal), decreasing = T)[1:9]), collapse = "\n")
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://bronx.lehman.cuny.edu"&gt;bronx.lehman.cuny.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.cityofnewyork.us"&gt;data.cityofnewyork.us&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.hawaii.gov"&gt;data.hawaii.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.illinois.gov"&gt;data.illinois.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.ny.gov"&gt;data.ny.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.ok.gov"&gt;data.ok.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.oregon.gov"&gt;data.oregon.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://explore.data.gov"&gt;explore.data.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.metrochicagodata.org"&gt;www.metrochicagodata.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Half of these portals federate &lt;code&gt;explore.data.gov&lt;/code&gt;, which has quite a few datasets, and the JSON
files seem to just include some of the &lt;code&gt;explore.data.gov&lt;/code&gt; data. I think these
files have only the first 1000 datasets, and I haven’t figured out how to look
at the next pages, so I’ll focus the present analysis on portals with fewer
than 1000 datasets.&lt;/p&gt;

&lt;h2 id="my-curiousity-about-file-formats"&gt;My curiousity about file formats&lt;/h2&gt;
&lt;p&gt;I’ve recently become curious about what formats the datasets come from. When
tabular data get loaded into a Socrata data portal, they get converted to a
tabular representation within the portal software. From that, they get converted
to a range of different tabular formats.&lt;/p&gt;

&lt;p&gt;The Socrata data portal doesn’t explicitly store the source format because of
how the import process works. Most of the data &lt;a href="http://blog.scraperwiki.com/2012/07/31/do-all-analysts-use-excel/"&gt;probably come from Excel&lt;/a&gt;,
and the data that aren’t from Excel typically come from inside of a government
network where policies would make it inconvenient to expose the database to the
world. Because of this, Socrata doesn’t query database servers. Instead, data
publishers write middlemen that act as both database clients and Socrata clients.
They query the database and then make &lt;a href="http://dev.socrata.com/publishers/getting-started"&gt;web requests&lt;/a&gt;
to the Socrata portal.&lt;/p&gt;

&lt;h2 id="datajson-contains-file-format-information"&gt;&lt;code&gt;/data.json&lt;/code&gt; contains file format information&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;/data.json&lt;/code&gt; endpoint contains a file format field per the Project Open Data
schema. This refers to the format of the data as served from the Socrata portal,
not the format it was stored in before it got to the Socrata portal. But this
still tells us something about the source file formats.&lt;/p&gt;

&lt;p&gt;People sometimes upload things that Socrata doesn’t interpret as tables. PDFs are
a major example. Other times, people upload or link to
files that could be tables but don’t specify that they are tables; those are called
“external links”. Read more on dataset types &lt;a href="/!/open-by-default#types-of-visualizations-on-socrata-portals"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Data formats are represented in two fields, &lt;code&gt;format&lt;/code&gt; and &lt;code&gt;distribution&lt;/code&gt;. &lt;code&gt;distribution&lt;/code&gt;{#distribution}
seems to contain all of the different available formats. If the data are imported as
tabular data, it contains CSV, JSON, XML, &amp;amp;c., all served from the Socrata site.
And if the data are external links, it will contain a few external links, still
specifying the file types. The &lt;code&gt;format&lt;/code&gt; field contains one of the formats that are
specified in the &lt;code&gt;distribution&lt;/code&gt; field. I think it’s just the first of the formats.
For the present analysis, I’m using the &lt;code&gt;format&lt;/code&gt; field.&lt;/p&gt;

&lt;p&gt;Recall that the present dataset of datasets counts federated datasets multiple times.
The following plot shows the file types of the deduplicated dataset dataset, across
all portals.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/deduplicated.png"&gt;&lt;img src="figure/deduplicated.png" alt="Formats of datasets across all portals" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And here are some of the main types by portal, counting federated datasets in all of their portals.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/all-formats.png"&gt;&lt;img src="figure/all-formats.png" alt="Data formats on all the portals" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;csv&lt;/code&gt; mostly refers
to data that Socrata represents as a table; this is the sort of data that Socrata
can convert to a range of different tabular data formats.
It is also my &lt;a href="http://csvsoundsystem.com"&gt;preferred file format&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Everything that is not CSV appears to be an external link.&lt;/p&gt;

&lt;h2 id="csv"&gt;CSV&lt;/h2&gt;
&lt;p&gt;Most datasets are CSV (8143 of 15699).
I was curious as to how this varies by portal and over time, and the following image
addresses that.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/csv-cum-facet.png"&gt;&lt;img src="figure/csv-cum-facet.png" alt="Dataset formats by portal over time" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The image above contains one plot per data portal. The x-axis of each plot is the date,
the y-axis is the proportion&lt;sup id="fnref:proportion"&gt;&lt;a href="#fn:proportion" class="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; of datasets that are tabular (CSV), and the
width of the line is the number of datasets on the portal.
For example, if there were 100 datasets on a portal in June 2011 and 80 were CSV, the
line would be near the top of the graph and quite skinny at June 2011.&lt;/p&gt;

&lt;p&gt;We can thus see how many datasets each portal has and what the different formats are.&lt;/p&gt;

&lt;h2 id="some-interesting-portals"&gt;Some interesting portals&lt;/h2&gt;
&lt;p&gt;Some portals have only CSV data (like &lt;code&gt;data.medicare.gov&lt;/code&gt;), but most contain
other data. I am curious both as to what other data formats they have and what
prompted the shifts in dataset format.&lt;/p&gt;

&lt;p&gt;Missouri mostly has PDFs.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/mo.png"&gt;&lt;img src="figure/mo.png" alt="Data formats on data.mo.gov" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also interesting about Missouri is that it federates &lt;a href="https://data.kcmo.org/"&gt;Kansas City&lt;/a&gt;,
which didn’t appear in my list of portals.&lt;/p&gt;

&lt;p&gt;I know I said I’d focus on portals with fewer than 1000 datasets, but Lehman College is
interesting because it has lots of zipped files.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/lehman.png"&gt;&lt;img src="figure/lehman.png" alt="Data formats on bronx.lehman.cuny.edu" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;San Francisco has a lot of CSVs, a lot of externally linked zip files,
and a lot of externally linked files of unknown format.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/sf.png"&gt;&lt;img src="figure/sf.png" alt="Data formats on data.sfgov.org" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="determination-of-external-link-file-formats"&gt;Determination of external link file formats&lt;/h2&gt;
&lt;p&gt;It looks like the format of external links is determined by the file name.
For example, Edmonton’s
&lt;a href="https://data.edmonton.ca/Transportation/Road-and-Traffic-Updates/5ggc-prfp?"&gt;Road and Traffic Updates&lt;/a&gt;
are marked as &lt;code&gt;application/rss+xml&lt;/code&gt; because the external link,
&lt;a href="http://www.trumba.com/calendars/construction-and-special-events-road-closures.rss"&gt;http://www.trumba.com/calendars/construction-and-special-events-road-closures.rss&lt;/a&gt;,
ends in &lt;code&gt;.rss&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In contrast, the &lt;a href="https://data.maryland.gov/d/ywbg-ptfh"&gt;Maryland Land Use/ Land Cover: 1973, 2002, 2010&lt;/a&gt;
dataset is marked as having the format &lt;code&gt;application/octet-stream&lt;/code&gt; because the
external link, &lt;a href="http://planning.maryland.gov/OurWork/landUseDownload.shtml"&gt;http://planning.maryland.gov/OurWork/landUseDownload.shtml&lt;/a&gt;,
ends in &lt;code&gt;.shtml&lt;/code&gt;.&lt;/p&gt;

&lt;!-- sqldf("select title, 'https://' || portal || '/d/' || identifier AS portalURL, accessURL from catalog where identifier = 'ywbg-ptfh'", dbname = '/tmp/catalog.db') --&gt;

&lt;h2 id="dates-of-significant-changes"&gt;Dates of significant changes&lt;/h2&gt;
&lt;p&gt;A few portals have only CSV data since the beginning, but most have had other formats.
Looking at the plots, we can see dates where there was a sudden change in the proportion
of datasets that were CSV.&lt;/p&gt;

&lt;h3 id="sudden-changes-at-the-beginning"&gt;Sudden changes at the beginning&lt;/h3&gt;
&lt;p&gt;When the first dataset gets uploaded, the proportion of datasets that are CSV is either
zero or one. Thus, the line for all of these datasets starts either at zero or one.
Most datasets sharply change after that; &lt;code&gt;data.austintexas.gov&lt;/code&gt; and &lt;code&gt;data.mo.gov&lt;/code&gt; are
examples.&lt;/p&gt;

&lt;p&gt;Others stay at this level for quite a while because no datasets were uploaded for a
while. &lt;code&gt;data.raleighnc.gov&lt;/code&gt; is an example of this. Here are its first ten datasets.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;created&lt;/th&gt;
      &lt;th&gt;format&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/s68n-gffw"&gt;Building Permit Data&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-03-14&lt;/td&gt;
      &lt;td&gt;text/csv&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/pep8-sb8v"&gt;Building Permit Data&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-03-14&lt;/td&gt;
      &lt;td&gt;text/csv&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/fuys-kh3c"&gt;City of Raleigh Quickfacts&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-19&lt;/td&gt;
      &lt;td&gt;text/csv&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/g3uq-k7zm"&gt;Raleigh Parking&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/jrpi-4amz"&gt;Raleigh Electric Utilities 2011&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/fcx2-d4t3"&gt;Raleigh Communications 2011&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/46tk-23jt"&gt;Raleigh Buildings 2011&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/3fmi-wyx6"&gt;Raleigh Parks and Trails&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/pwv5-a5ca"&gt;Raleigh Trail Areas&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.raleighnc.gov/d/apbx-xr7f"&gt;Family Income In The Past 12 Months&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2013-02-28&lt;/td&gt;
      &lt;td&gt;text/csv&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The first two datasets were uploaded in the middle of March 2012 and were CSV format,
making the datasets 100% CSV. The next was uploaded in the middle of February 2013 and
was also CSV, so the proportion was still 100% CSV. At the end of the month, six
zip files were uploaded, reducing the proportion to 33% CSV.&lt;/p&gt;

&lt;h3 id="sudden-changes-after-the-beginning"&gt;Sudden changes after the beginning&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;data.sfgov.org&lt;/code&gt; had a sudden change in the proportion of datasets that were CSV, but
it was after a long while, so a lot of related datasets might have been uploaded all
at once. Let’s look at when datasets were uploaded.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/sf-changes.png"&gt;&lt;img src="figure/sf-changes.png" alt="Formats of newly open San Francisco datasets over time" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This has the quite similar information to the earlier plots, but it’s a bit more precise.
San Francisco added lots of datasets in January 2012, November 2012, and December 2012, and proportionately
few of these datasets were CSV. What were they?&lt;/p&gt;

&lt;p&gt;Here are ten of the January datasets.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;created&lt;/th&gt;
      &lt;th&gt;format&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/2ivi-ywmk"&gt;Arterial Streets of San Francisco (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/2xc9-is4u"&gt;Orthophoto 1ft resolution (1993) - (Zipped MrSID Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/3vyz-qy9p"&gt;City Lots (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/4aaa-ycik"&gt;Census 2000 Block Group (No Water) (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/4drs-6tjy"&gt;Orthophoto 1ft (1993) - Treasure Island (Zipped MrSID Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/4mzs-yjt7"&gt;SFPD Sectors&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/5aii-qc4e"&gt;SFPD Crime Reporting Plots (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/5fxg-wene"&gt;Neighborhood Marketplace Initiative Corridors (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/5rn4-fswj"&gt;San Francisco Basemap Street Centerlines (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href="https://data.sfgov.org/d/5sny-6aph"&gt;The Presidio of San Francisco (Zipped Shapefile Format)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;2012-01-01&lt;/td&gt;
      &lt;td&gt;application/zip&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;It looks like January is mostly externally linked, zipped shapefiles. Most of the
datasets say “shapefile” in their &lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; or &lt;a href="#distribution"&gt;&lt;code&gt;distribution&lt;/code&gt;&lt;/a&gt; fields.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/sf-shapefile.png"&gt;&lt;img src="figure/sf-shapefile.png" alt="Formats of newly open San Francisco datasets over time" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And a lot of the rest of the January files look like zipped shapefiles, even though the
titles and descriptions don’t say so.&lt;/p&gt;

&lt;p&gt;So San Francisco suddenly uploaded a bunch of shapefiles in January and November/December.&lt;/p&gt;

&lt;h3 id="plateaus-of-dataset-counts"&gt;Plateaus of dataset counts&lt;/h3&gt;
&lt;p&gt;Some of the plots make it look like lots of datasets were suddenly uploaded one time
and no datasets were uploaded again. This is mainly for the
&lt;a href="#cutoff-at-1000"&gt;portals with more than 1000 datasets&lt;/a&gt;,
so I think this is because we’re seeing only the first 1000 datasets.&lt;/p&gt;

&lt;h2 id="csv-pdf-zip-and-octet-stream"&gt;CSV, pdf, zip and octet-stream&lt;/h2&gt;
&lt;p&gt;Based on the examples above, it seems like a lot of datasets are PDF, zip or unknown
external links. I made the following series of plots to check it. It is just like the
&lt;a href="#csv"&gt;similar image above&lt;/a&gt; except for the y-axes; instead of representing the
proportion of datasets that are CSV, each y-axis represents the proportion of datasets
that are CSV, PDF, zip or unknown external links.&lt;/p&gt;

&lt;p&gt;&lt;a href="figure/csv-pdf-zip-octet-cum-facet.png"&gt;&lt;img src="figure/csv-pdf-zip-octet-cum-facet.png" alt="Dataset formats by portal over time" class="wide" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of the curves are pretty straight and stay near 1, meaning that the proportion doesn’t
change much and that the proportion is quite high. Thus, it looks like most datasets are
either CSV, pdf, zip or external links of unknown format.&lt;/p&gt;

&lt;h2 id="conclusions"&gt;Conclusions&lt;/h2&gt;

&lt;h3 id="formats"&gt;Formats&lt;/h3&gt;
&lt;p&gt;I was mainly wondering about the source formats of the data. It turns out that most datasets
are tables. Aside from tables, there are lots of externally linked files, mostly PDFs and zip archives.&lt;/p&gt;

&lt;h3 id="shapefiles"&gt;Shapefiles&lt;/h3&gt;
&lt;p&gt;I’ve been thinking recently about how to infer the organizational structure of a municipality
based on the open data that they release, and the finding with the San Francisco shapefiles
alludes to this. It might be that one department within the San Francisco government manages
and uses most of the geospatial data and that the open data team happened to work with them
in January, November and December of 2012.&lt;/p&gt;

&lt;h2 id="future-study"&gt;Future study&lt;/h2&gt;
&lt;p&gt;This got me thinking about other ways of studying file formats.&lt;/p&gt;

&lt;h3 id="the-attribution-field"&gt;The attribution field&lt;/h3&gt;
&lt;p&gt;Socrata’s SODA 1 API, which I’ve &lt;a href="/!/socrata-summary/#download-dataset-metadata"&gt;used before&lt;/a&gt;,
contains an &lt;code&gt;attribution&lt;/code&gt; field, which references the URL from
which the dataset was taken.&lt;sup id="fnref:attribution"&gt;&lt;a href="#fn:attribution" class="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; This would be one
way of figuring out the source format, or at least some related information about the source.&lt;/p&gt;

&lt;h3 id="externally-linked-csvs"&gt;Externally linked CSVs&lt;/h3&gt;
&lt;p&gt;Not all of the CSV-formatted datasets necessarily come from Socrata; some might be links
to external CSV files. There is enough information in &lt;code&gt;/data.json&lt;/code&gt; to determine which of
these categories a CSV dataset falls into.&lt;/p&gt;

&lt;h3 id="determining-the-formats-of-external-links"&gt;Determining the formats of external links&lt;/h3&gt;
&lt;p&gt;It looks to me like the format type of external links is determined based on the file
extension of the URL; &lt;code&gt;octet-stream&lt;/code&gt; datasets seem to correspond to URLs without file
extensions or with file extensions like &lt;code&gt;aspx&lt;/code&gt; that don’t clearly correspond to a
particular file types. One could determine the formats of these datasets by
downloading the files.&lt;/p&gt;

&lt;h2 id="footnotes"&gt;Footnotes&lt;/h2&gt;

&lt;div class="footnotes"&gt;
  &lt;ol&gt;
    &lt;li id="fn:proportion"&gt;
      &lt;p&gt;It’s actually a tad bit more complicated than that. These dates are the
creation dates of the datasets that are available today; I do not know about datasets
that were historically on the portal and have since been deleted.&lt;a href="#fnref:proportion" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id="fn:attribution"&gt;
      &lt;p&gt;I presume that this is entered manually.&lt;a href="#fnref:attribution" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2013-08-21:/!/open-by-default/index.html</id>
    <title type="html">Open by default</title>
    <published>2013-08-21T07:00:00Z</published>
    <updated>2013-08-21T07:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/open-by-default/index.html"/>
    <content type="html">&lt;p&gt;The first of Sunlight Foundation’s 32
&lt;a href="http://sunlightfoundation.com/opendataguidelines/"&gt;Open Data Policy Guidelines&lt;/a&gt;
is to “Set The Default To Open”.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Most public records systems, including the Freedom of Information Act itself, are systems of reactive disclosure – meaning that a question has to be asked before an answer given; public information requested, before it is disclosed.&lt;/p&gt;

  &lt;p&gt;Proactive disclosure is the opposite. Proactive disclosure is the release of public information – online and in open formats (see Provisions 8 and 9) – before it is asked for. This is no simple task, but, in a way, it’s what all “open data” is aiming to accomplish. Setting the default to open means that the government and parties acting on its behalf will make public information available proactively and that they’ll put that information within reach of the public (online), with low to no barriers for its reuse and consumption. Open formats may help us maximize on the value we can extract from certain kinds of public data today, but to ensure that data publishing is sustained and, in fact, made easier over time, we need to reset the default for how data is released and disclosed.&lt;/p&gt;

  &lt;p&gt;Setting the default to open is about living up to the potential of our information, about looking at comprehensive information management, and making determinations that fall in the public interest. It’s about purely practical government improvements, too, and taking steps that not only keep government systems up to date, but ensure that we have the foresight to survive changes in technology that we can’t predict.&lt;/p&gt;

  &lt;p&gt;Usually, for information to be defined as public, important restrictions have already been applied. Therefore, policy language can be used to outline that “all public data and information must be considered open and accessible.” Whether listed as part of a statement of intent (as Austin, Texas does; a concept explored more in Provision 21), as direction to a new oversight authority (Provision 22), or as the underlying aim of new data guidance (Provision 20), openness by default is a critical tool in crafting open data policies that are both ambitious and sustainable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After discovering something on Socrata data portals, I remarked that
software can encourage this practice of making data open by default.&lt;/p&gt;

&lt;h2 id="types-of-visualizations-on-socrata-portals"&gt;Types of visualizations on Socrata portals&lt;/h2&gt;
&lt;p&gt;I previously &lt;a href="/!/socrata-summary"&gt;downloaded&lt;/a&gt; metadata about all of
the datasets on all of the Socrata portals, and I continue to find
interesting things in these data. Let’s look at the different types
of visualizations (“&lt;a href="/!/socrata-genealogies#term-view"&gt;views&lt;/a&gt;”) on the portals.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/not_boring.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;(I excluded tables and external links from the above plot.)&lt;/p&gt;

&lt;p&gt;I was somewhat surprised to see forms and calendars in the portals.
I’ve &lt;a href="/!/open-calendars"&gt;previously&lt;/a&gt; written about why I think Socrata calendars are cool,
so now I’m just going to talk about forms.&lt;/p&gt;

&lt;h3 id="popularity-of-forms"&gt;Popularity of forms&lt;/h3&gt;
&lt;p&gt;Much of the goal of these portals is to open up existing government data, but
&lt;a href="https://data.wa.gov/Economics/Broadband-Project-Data-Entry/38rz-krmg?"&gt;forms&lt;/a&gt; provide a way for citizens to create data.
lets you enter data. A bunch of people have implemented them, but none seems to get accessed much.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/form_use_3.png" alt="Form use by portal" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;I’m gonna remove opendata.socrata.com to make that easier to read.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/form_use_4.png" alt="Form use by portal, excluding opendata.socrata.com" class="wide" /&gt;&lt;/p&gt;

&lt;h3 id="cool-forms"&gt;Cool Forms&lt;/h3&gt;
&lt;p&gt;I hadn’t seen &lt;a href="https://nmfs.socrata.com"&gt;nmfs.socrata.com&lt;/a&gt; before.
It belongs to the &lt;a href="http://www.nmfs.noaa.gov"&gt;National Oceanic and Atmospheric Administration Fisheries Service&lt;/a&gt;,
which apparently used &lt;a href="https://nmfs.socrata.com/Government/2011-Aquaculture-Public-Comments-Form/u5id-8nqp"&gt;a Socrata form&lt;/a&gt; to power a
&lt;a href="http://www.nmfs.noaa.gov/aquaculture/policy2/"&gt;policy comments website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;New York made a form for &lt;a href="https://data.ny.gov/dataset/Give-Feedback/fq3e-q75i?"&gt;feedback on the portal&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;World Bank Open Finances made a
&lt;a href="https://finances.worldbank.org/dataset/Global-Open-Data-Calendar-Entry-Form/qdbh-rfd3?"&gt;form&lt;/a&gt;
that populates an
&lt;a href="https://finances.worldbank.org/dataset/Global-Open-Data-Calendar/g4sx-dwxc"&gt;open data events calendar&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id="relevance-to-software"&gt;Relevance to software&lt;/h2&gt;
&lt;p&gt;The three examples of Socrata forms show us how we can turn user input on a website into
open data automatically. Using a Socrata form to compose a dataset is quite inconvenient,
unreliable, limited, and other bad things, but I see this as a nice example of how software
can encourage that data be open by default. I previously
&lt;a href="http://thomaslevine.com/!/socrata-calendars#opening-data-at-their-sources"&gt;hinted&lt;/a&gt; at this,
but now I have two specific ideas as to how software can encourage that data be open by default.&lt;/p&gt;

&lt;h3 id="standard-formats"&gt;1. Standard formats&lt;/h3&gt;
&lt;p&gt;If you run any sort of involved website, you are probably already storing data in some
reasonably standard way, and you probably could send it to a data portal somewhat easily.&lt;/p&gt;

&lt;h4 id="opening-user-entered-application-data-on-your-websites-database"&gt;Opening user-entered application data on your website’s database&lt;/h4&gt;
&lt;p&gt;One advantage of the Socrata form approach is that the data go automatically into a
reasonably standard format (a Socrata dataset). It happens that most websites work this
way, except that the standard format is something like MySQL.&lt;/p&gt;

&lt;p&gt;A notable difference is that database software generally doesn’t concern itself as
strongly with opening the data. Many websites have HTTP APIs, but few will give out
direct access to their databases. And even if they did this, it wouldn’t provide the
various cataloging and format conversion features that people expect of data portals.
This is why we make data portals that import from these databases and provide all the
fancy features.&lt;/p&gt;

&lt;p&gt;If you have a website that stores information in a standard database (like MySQL) and
you separate the private information from the public information, you already can quite
safely and easily have it sent to a data portal.&lt;/p&gt;

&lt;p&gt;If you are making a new website and care about open data, try to choose a common
database for which integrations will already exist.&lt;/p&gt;

&lt;h4 id="storing-user-entered-application-data-directly-in-a-data-portal"&gt;Storing user-entered application data directly in a data portal&lt;/h4&gt;
&lt;p&gt;If you have a simple website, maybe you don’t have to run your own database
and write your own web APIs. You could store the data directly in the data portal
and query it from the data portal. If this is powerful enough for you, it
simplifies your database management, and it naturally makes your data open by default.&lt;/p&gt;

&lt;h4 id="opening-data-from-some-other-software"&gt;Opening data from some other software&lt;/h4&gt;
&lt;p&gt;Every time you save something in a computer program, you are creating some sort
of data, just like when you fill out a form on an open data portal.
If you have purchased a software service, you might not have access to the
underlying database, but you can still send it to a data portal.&lt;/p&gt;

&lt;p&gt;When a lot of people use services like these, the services’ protocols naturally
become standard, so it becomes worthwhile to write tools that pull data from these
services into some standard place like a data portal. Using a standard service
with lots of users and integrations should make it easier for you to get the data
into a data portal.&lt;/p&gt;

&lt;h3 id="explicit-separation-between-public-and-private-data"&gt;2. Explicit separation between public and private data&lt;/h3&gt;
&lt;p&gt;With a questionnaire, you might be able to just say that all of the responses are
private or that all are public. With other datasets, you might be able to say that
certain fields are private and others are public; in a database of employees, name
and salary can be public, but Social Security number can’t.&lt;/p&gt;

&lt;p&gt;Things aren’t always this simple. With something like project management software,
some records/documents should be private and others should be public. Many of the
entries in project management software are probably safe for public disclosure,
but there might be some private information; for example, I’ve put passwords inside
calendar entries and issue tracker tickets.&lt;/p&gt;

&lt;p&gt;Project management software, email clients, calendars, web browsers and image
editors all contain rich data that can help people understand how government
and other organizations work, so we should find ways of separating the public
information and opening that. Software can help with this.&lt;/p&gt;

&lt;p&gt;Separate public information and private information from the beginning, and it
should be easier to open the data that is behind all of these applications.
The user interface can expose the separation between public and private and
encourage that information public by default.&lt;/p&gt;

&lt;h2 id="things-to-think-about"&gt;Things to think about&lt;/h2&gt;
&lt;p&gt;Think about what programs you and others are already using, especially if you
don’t think of them as data programs, and think about how you can open the data in these programs.
A program’s data will be easy to open if the program already stores its data in
a standard format on the internet and it clearly separates public data from
private data.&lt;/p&gt;

&lt;p&gt;Also think about how we can make software that follows the policy guideline of
open data by default. I’ve proposed that clear separations between public and
private data is part of this and that standard storage methods is another, but
there are surely other relevant features.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2013-08-19:/!/reciprocity/index.html</id>
    <title type="html">Reciprocity</title>
    <published>2013-08-19T07:00:00Z</published>
    <updated>2013-08-19T07:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/reciprocity/index.html"/>
    <content type="html">&lt;p&gt;Last year, while on my way to the &lt;a href="http://www.ire.org/nicar/"&gt;NICAR&lt;/a&gt;
conference, I found myself in Chicago for a couple hours waiting for
a train. This was enough time for me to lunch with a friend who was
working at the University of Chicago.&lt;/p&gt;

&lt;p&gt;I was about to catch a bus towards the university when I realized
that my smallest denomination of currency was a $5 bill. Since the buses
only take exact change, I looked around for a way to break it. I asked a
person who was waiting for the bus with me if she could break it, and she
said she didn’t have change.&lt;/p&gt;

&lt;p&gt;We both wound up getting on the same bus, and I got on first.
I told the bus driver that the $5 was for both of us, and then I promptly
walked to the back of the bus, still a few yards ahead of the other person.&lt;/p&gt;

&lt;p&gt;Shortly after I sat down, this person made her way to the back of the bus,
gave me two dollars and then found an empty seat towards the middle of the bus.&lt;/p&gt;

&lt;p&gt;This person went slightly out of her way to pay me for the bus ride that
I gave her. Reciprocity is cool.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2013-08-14:/!/socrata-metrics-api/index.html</id>
    <title type="html">How to use Socrata's site metrics API</title>
    <published>2013-08-14T07:00:00Z</published>
    <updated>2013-08-14T07:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/socrata-metrics-api/index.html"/>
    <content type="html">&lt;p&gt;The site metrics API on a Socrata open data portal tells you some
pretty cool things about how people are using the portal. I’m going
to show you how to get use the API.&lt;/p&gt;

&lt;h2 id="getting-access-to-the-site-metrics-data"&gt;Getting access to the site metrics data&lt;/h2&gt;
&lt;p&gt;The site metrics data are private by default, so you first need to get
access to them.&lt;/p&gt;

&lt;p&gt;One way to get access is to become a
“&lt;a href="https://data.oaklandnet.com/api/site_metrics.json?start=1375315200000&amp;amp;end=1376438399999&amp;amp;_=1376438538384"&gt;domain member&lt;/a&gt;”. I don’t know
exactly how you do that, but it surely involves working for organization
that is publishing the data.&lt;/p&gt;

&lt;p&gt;You can also get access if a portal administrator makes the site metrics
public. She can do this by talking to a support person from Socrata.&lt;/p&gt;

&lt;p&gt;Out of the 60 portals I know about, 12 currently publish the analytics page openly.
(I run &lt;a href="https://github.com/tlevine/socrata-nominate/blob/master/has_analytics.sh"&gt;this script&lt;/a&gt; to check.)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://data.austintexas.gov/analytics"&gt;data.austintexas.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.cityofnewyork.us/analytics"&gt;data.cityofnewyork.us&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.hawaii.gov/analytics"&gt;data.hawaii.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://explore.data.gov/analytics"&gt;explore.data.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://bronx.lehman.cuny.edu/analytics"&gt;bronx.lehman.cuny.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.sfgov.org/analytics"&gt;data.sfgov.org&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.baltimorecity.gov/analytics"&gt;data.baltimorecity.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.oregon.gov/analytics"&gt;data.oregon.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.raleighnc.gov/analytics"&gt;data.raleighnc.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.ok.gov/analytics"&gt;data.ok.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.seattle.gov/analytics"&gt;data.seattle.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://data.montgomerycountymd.gov/analytics"&gt;data.montgomerycountymd.gov&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The site analytics page gets its data from the site metrics API, and
that API becomes available to the public when the site analytics page is made
available to the public.&lt;/p&gt;

&lt;h2 id="using-the-api"&gt;Using the API&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;GET /api/site_metrics.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The whole API uses the endpoint &lt;code&gt;/api/site_metrics.json&lt;/code&gt;.
You access this endpoint by making a typical GET request; you don’t need
any special cookie, header, or API key.&lt;/p&gt;

&lt;p&gt;Two query arguments are required.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;start&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;end&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are both dates, represented as milliseconds since January 1, 1970.
(It’s something like “&lt;script&gt;document.write((new Date()).getTime())&lt;/script&gt;&lt;noscript&gt;1376439688459&lt;/noscript&gt;”.)
These arguments define the range within which the metrics will be aggregated.&lt;/p&gt;

&lt;p&gt;This endpoint exposes three methods.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Site-wide statistics (no method)&lt;/li&gt;
  &lt;li&gt;Site-wide statistics by time interval (&lt;code&gt;series&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Most popular (&lt;code&gt;top&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each method is discussed below.&lt;/p&gt;

&lt;h3 id="site-wide-statistics-no-method"&gt;Site-wide statistics (no method)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;GET /api/site_metrics.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you specify no method argument, you’ll get some statistics
about the entire portal, such as the total number of datasets
created since the beginning of time (&lt;code&gt;datasets-created-total&lt;/code&gt;),
the number of datasets created within the date range specified
by &lt;code&gt;start&lt;/code&gt; and &lt;code&gt;end&lt;/code&gt; (&lt;code&gt;datasets-created&lt;/code&gt;), and the number of
rows of data that were accessed via the API within the date
range (&lt;code&gt;rows-accessed-api&lt;/code&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl https://data.oregon.gov/api/site_metrics.json?start=1375315200000&amp;amp;end=1376438399999
{
  "datasets-created-total" : 5623,
  "datasets-deleted-total" : 4801,
  "datasets-created-blobby-total" : 113,
  "datasets-deleted-blobby-total" : 4,
  "datasets-created-href-total" : 13,
  "datasets-deleted-href-total" : 10,
  "rows-created-total" : 40757082,
  "rows-deleted-total" : 25546425,
  "page-views-total" : 2599228,
  "embeds-total" : 489504,
  "embeds" : 12094,
  "maps-created" : 99,
  "bytes-out" : 112213178897,
  "page-views" : 74530,
  "rows-loaded-api" : 20272,
  "rows-accessed-website" : 59636,
  "rows-loaded-download" : 8771634,
  "rows-accessed-api" : 611,
  "rows-loaded-website" : 778954,
  "rows-deleted" : 628998,
  "rows-accessed-rss" : 610,
  "maps-deleted" : 99,
  "filters-created" : 4995,
  "rows-loaded-widget" : 1347648,
  "rows-accessed-widget" : 67687,
  "geocoding-requests" : 10009,
  "users-created" : 645,
  "datasets-created" : 147,
  "js-page-view" : 68095,
  "datasets-deleted" : 122,
  "rows-accessed-download" : 379,
  "view-loaded" : 16599,
  "app-token-created" : 1,
  "charts-deleted" : 17,
  "shares" : 1,
  "rows-loaded-rss" : 26698,
  "bytes-in" : 658003507,
  "filters-deleted" : 4985,
  "charts-created" : 16,
  "rows-created" : 1040389,
  "comments" : 2
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="site-wide-statistics-by-time-interval-series"&gt;Site-wide statistics by time interval (&lt;code&gt;series&lt;/code&gt;)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;GET /api/site_metrics.json?method=series
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you want to get site-wide statistics by day, you could
use no method (above) and vary the start and end dates.
The series method lets you do something equivalent in one
HTTP request.&lt;/p&gt;

&lt;p&gt;This method requires an additional parameter, &lt;code&gt;slice&lt;/code&gt;.
Valid values include&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;DAILY&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;WEEKLY&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;MONTHLY&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;YEARLY&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The result is a list of associative arrays, each one
corresponding to a time interval and containing the same
metrics that we would see with no method.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl 'https://data.oregon.gov/api/site_metrics.json?start=1375315200000&amp;amp;end=1376438399999&amp;amp;method=series&amp;amp;slice=WEEKLY'
[ {
  "__start__" : 1374969600000,
  "metrics" : {
    ...
  },
  "__end__" : 1375574399999
}, {
  "__start__" : 1375574400000,
  "metrics" : {
    ...
  },
  "__end__" : 1376179199999
}, {
  ...
} ]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="most-popular-top"&gt;Most popular (&lt;code&gt;top&lt;/code&gt;)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;GET /api/site_metrics.json?method=top
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Return the most common entities of a particular type.
You specify the entity type with the required argument &lt;code&gt;top&lt;/code&gt;;
it can be any of the following.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;DATASETS&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;REFERRERS&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;SEARCHES&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;EMBEDS&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The output is always an associative array, but the schema
depends on the type of entity.&lt;/p&gt;

&lt;h4 id="top-datasets"&gt;Top Datasets&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;GET /api/site_metrics.json?method=top&amp;amp;top=DATASETS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This returns a mapping from &lt;a href="/!/socrata-genealogies#term-view"&gt;views&lt;/a&gt;
(represented by their &lt;a href="http://dev.socrata.com/docs/endpoints"&gt;4x4 ids&lt;/a&gt;)
to a view count (that is, the number of times someone opened the webpage for that view).&lt;/p&gt;

&lt;!--
To check that it's a view count rather than a download count
or some other count, look at the counts in these two pages.

https://data.oregon.gov/api/views/ffmj-ntaw.json
https://data.oregon.gov/api/site_metrics.json?start=1175315200000&amp;end=1376438399999&amp;method=top&amp;top=DATASETS
--&gt;

&lt;pre&gt;&lt;code&gt;curl 'https://data.oregon.gov/api/site_metrics.json?start=1375315200000&amp;amp;end=1376438399999&amp;amp;method=top&amp;amp;top=DATASETS'
{
  "nmjt-yuqx" : 5,
  "3sqh-pdgv" : 1,
  "hap2-76p2" : 1,
  "822n-er69" : 17,
  "dsje-kuhw" : 1,
  "8sad-79b5" : 75,
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can query the datasets with 
&lt;a href="http://dev.socrata.com/deprecated/querying-datasets"&gt;SODA 1&lt;/a&gt; or
&lt;a href="http://dev.socrata.com/docs/queries"&gt;SODA 2&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can get more information about these with the
&lt;a href="/!/socrata-summary#download-dataset-metadata"&gt;&lt;code&gt;/api/views&lt;/code&gt; endpoint&lt;/a&gt;.
I’m told that this endpoint is considered part of SODA 1.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;/api/views&lt;/code&gt; endpoint provides information about only one
&lt;a href="/!/socrata-genealogies#term-view"&gt;view&lt;/a&gt; per HTTP request.
The site analytics page uses the batches endpoint (&lt;code&gt;/api/batches&lt;/code&gt;)
to get metadata about several views at once.
I haven’t found any documentation on that, but I might document that eventually.&lt;/p&gt;

&lt;h4 id="top-referrers"&gt;Top Referrers&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;GET /api/site_metrics.json?method=top&amp;amp;top=REFERRERS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This also returns counts, presumably view counts. The root associative array
maps an origin (like &lt;code&gt;http://thomaslevine.com&lt;/code&gt;) to an associative
array, and that child associative array maps the rest of the URL
(like &lt;code&gt;/!/socrata-metrics-api/?foo=bar&lt;/code&gt;) to a count.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl 'https://data.oregon.gov/api/site_metrics.json?start=1375315200000&amp;amp;end=1376438399999&amp;amp;method=top&amp;amp;top=REFERRERS&amp;amp;_=1376451966200'
{
  "https://govspace.oregon.gov" : {
    "/community/forall/testdrive/jasonstest?view=overview" : 2,
    "/index.jspa" : 1,
    "/community/agencies/das/geo/gpl" : 1,
    "/index.jspa?showhomepage=true" : 1,
    "/community/forall/testdrive/jasonstest" : 18
  },
  ...,
  "http://www.state.or.us" : {
    "/DAS/Pages/mobile_bldgclose.aspx" : 2,
    "/Pages/do_business_in_oregon.aspx" : 1,
    "/Pages/sitemap.aspx" : 1,
    "/docs/pop_box/news_story_template.doc" : 1,
    "/ODA/FSD/Pages/recalls.aspx" : 1,
    "/DAS/pages/bldg_close/index.aspx" : 1
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id="top-searches"&gt;Top Searches&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;GET /api/site_metrics.json?method=top&amp;amp;top=SEARCHES
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Searches are separated into dataset searches and user searches.
Within each, a mapping from search terms to counts is returned.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl 'https://data.oregon.gov/api/site_metrics.json?start=1375315200000&amp;amp;end=1376438399999&amp;amp;method=top&amp;amp;top=SEARCHES&amp;amp;_=1376451966200'
{
  "top-user-searches" : {
    "Tiffany.Koss@state.or.us" : 1
  },
  "top-dataset-searches" : {
    "Oregon Public Meetings" : 2,
    "copy of 501 c3" : 1,
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id="top-embeds"&gt;Top Embeds&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;GET /api/site_metrics.json?method=top&amp;amp;top=EMBEDS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This returns the same format as the top referrers; the root associative array
maps an origin (like &lt;code&gt;http://thomaslevine.com&lt;/code&gt;) to an associative
array, and that child associative array maps the rest of the URL
(like &lt;code&gt;/!/socrata-metrics-api/?foo=bar&lt;/code&gt;) to a count.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl 'https://data.oregon.gov/api/site_metrics.json?start=1375315200000&amp;amp;end=1376438399999&amp;amp;method=top&amp;amp;top=EMBEDS'
{
  "http://translate.googleusercontent.com" : {
    "/translate_c?depth=1&amp;amp;hl=fa&amp;amp;prev=/search%3Fq%3Dmaking%2BElectric%2Bhemlock%2Blaunch%26biw%3D1024%26bih%3D670&amp;amp;rurl=translate.google.com&amp;amp;sl=en&amp;amp;u=http://www.oregon.gov/osmb/pages/access/access.aspx&amp;amp;usg=ALkJrhi2xJIclSRZsqxBQIg-pjV-38Mlbw" : 3
  },
  "https://govspace.oregon.gov" : {
    "/community/forall/testdrive/jasonstest?view=overview" : 2,
    "/community/forall/testdrive/jasonstest" : 4
  },
  "https://t.co" : {
    "/IXXONPIGWT" : 1
  },
  "https://www.google.ca" : {
    "/" : 2
  },
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id="related"&gt;Related&lt;/h2&gt;
&lt;p&gt;Socrata has a &lt;a href="http://support.socrata.com/entries/20494886-What-do-the-different-metrics-in-the-Socrata-Analytics-Pages-mean-"&gt;support page&lt;/a&gt; about the analytics page.&lt;/p&gt;
</content>
  </entry>
</feed>

