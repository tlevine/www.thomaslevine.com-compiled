<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://www.thomaslevine.com/</id>
  <title>Thomas Levine</title>
  <updated>2014-02-22T00:00:00Z</updated>
  <link rel="alternate" href="http://www.thomaslevine.com/"/>
  <link rel="self" href="http://www.thomaslevine.com/!/feed.xml"/>
  <author>
    <name>Thomas Levine</name>
    <uri>http://www.thomaslevine.com</uri>
  </author>
  <entry>
    <id>tag:www.thomaslevine.com,2014-02-22:/!/zombie-links/index.html</id>
    <title type="html">Zombie links on data catalogs</title>
    <published>2014-02-22T00:00:00Z</published>
    <updated>2014-02-22T00:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/zombie-links/index.html"/>
    <content type="html">&lt;p&gt;After I wrote about
&lt;a href="/!/dead-links-on-data-catalogs"&gt;dead links on data catalogs&lt;/a&gt;,
some people commented that the links were less dead than I’d thought.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://twitter.com/statshero/status/424147773852622848"&gt;&lt;img src="trentino.png" alt="Anecdotally I don't think that @DatiTrentinoit has so many broken links. Check validator? @thomaslevine http://thomaslevine.com/!/data-catalog-dead-links/" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://twitter.com/waldojaquith/status/424026174508261376"&gt;&lt;img src="openva.png" alt="@thomaslevine You've got ~45% of data․openva․com datasets missing. I just audited 75% of them, and found just 2 missing. Any idea what's up?" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some explanations were proposed. Samuele and Jindřich both suggested that
the CKAN FileStore doesn’t support HEAD requests.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://twitter.com/_rshk/status/424208140016418816"&gt;&lt;img src="samuele.png" alt="@DatiTrentinoit @statshero @thomaslevine Ckan returns 404 on HEAD requests, that's the problem.." /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://twitter.com/jindrichmynarz/status/428194318063370241"&gt;&lt;img src="jindrich.png" alt="" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And &lt;a href="http://waldo.jaquith.org/"&gt;Waldo&lt;/a&gt;
suggested that I might be checking for status code 200 but
receiving status code 303 (redirect) from OpenVA.&lt;/p&gt;

&lt;p&gt;So what was going on?&lt;/p&gt;

&lt;h2 id="not-reasons"&gt;Not reasons&lt;/h2&gt;
&lt;p&gt;I considered the two possibilities that were mentioned above, and
I don’t think either of them was the issue.&lt;/p&gt;

&lt;h3 id="head"&gt;HEAD&lt;/h3&gt;
&lt;p&gt;CKAN does just fine on HEAD requests.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;url = 'http://dati.trentino.it/storage/f/2013-06-16T114537/_EBmYVk.csv'
import requests

get = requests.get(url)
head = requests.head(url)

print(get.status_code)
# 200
print(head.status_code)
# 200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So I don’t think the issue was that CKAN returns 404 on HEAD requests.&lt;/p&gt;

&lt;h3 id="status-code"&gt;Status code&lt;/h3&gt;
&lt;p&gt;I counted a link as alive if and only if it returned a status code of 200.
Could the issue be that I needed to check for other status codes? Specifically,
could it be that the URLs for files hosted on some CKAN FileStores are redirects
rather than final URLs?&lt;/p&gt;

&lt;p&gt;URLs from the CKAN FileStore should not be an issue because I didn’t check URLs
when the data were marked as being stored internally in the catalog.&lt;/p&gt;

&lt;p&gt;That said, it’s possible that people uploaded the data to the CKAN FileStore and
then told CKAN that it was an external link; it turns out that this was the case
for OpenVA&lt;/p&gt;

&lt;p&gt;Running this query&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT DISTINCT url FROM links WHERE catalog = 'data.openva.com' AND NOT is_link;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;yields three URLs with that characteristic.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://data.openva.com.s3.amazonaws.com/2013-06-30T21:27:16.600Z/2013.json
https://data.openva.com.s3.amazonaws.com/2013-12-16T03:06:56.875Z/sentencing.csv
https://data.openva.com.s3.amazonaws.com/2013-05-11T04:57:18.031Z/agency-websites.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;They have issues with SSL certificates,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;requests.head('https://data.openva.com.s3.amazonaws.com/2013-06-30T21:27:16.600Z/2013.json')
# SSLError: hostname 'data.openva.com.s3.amazonaws.com' doesn't match either of '*.s3.amazonaws.com', 's3.amazonaws.com'
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and they work just fine with unencrypted HTTP.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;requests.head('http://data.openva.com.s3.amazonaws.com/2013-06-30T21:27:16.600Z/2013.json').status_code
# 200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Moreover, there aren’t very many redirect status codes across all the links.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_no_redirects.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;Redirects are normally of status code 301 or 303, or at least in the 300-399
range. I followed redirects when I downloaded them, so this plot contains no
redirect status codes.&lt;/p&gt;

&lt;h2 id="reasons"&gt;Reasons&lt;/h2&gt;
&lt;p&gt;If the HEAD request thing and the redirect status code weren’t the issues,
what was?&lt;/p&gt;

&lt;p&gt;To figure this out, I tweaked my downloader and ran it on just the links that
had timed out or otherwise not responded; I didn’t run it on links that had
responded with error status codes like 404. I also pulled out the hostname of
the links. (For example, &lt;code&gt;thomaslevine.com&lt;/code&gt; of the URL of the page you’re
reading.) Then I looked at the errors I got back.&lt;/p&gt;

&lt;p&gt;I also looked around in the SQLite3 database in which I’d been storing
everything for this link analysis.&lt;/p&gt;

&lt;p&gt;It’s not like there was just one issue, of course.
Here are the main factors I see as leading to the strange results.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I didn’t fully parse links to datasets.&lt;/li&gt;
  &lt;li&gt;I had a low timeout on my HTTP requests (2 seconds).&lt;/li&gt;
  &lt;li&gt;I had duplicate data in my database.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="incompletely-parsed-urls"&gt;Incompletely parsed URLs&lt;/h3&gt;
&lt;p&gt;I looked at the different sorts of errors that I got when I requested links
to different hostnames.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_hostname_error.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;That the left-most bar, for the hostname &lt;code&gt;http:&lt;/code&gt;, is quite large and has
a lot of invalid URLs. Things that my hostname-parser detected as &lt;code&gt;http:&lt;/code&gt; are
usually invalid URLs.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[1] "http://"
[2] "http://www..ic.nhs.uk/catalogue/PUB09271/per-soc-ser-adu-soc-car-sur-eng-2011-12-fin-tables-charts.xls"
[3] "http://Gemeente-Den-Haag-open-data-Bodemenergie-restwarmtelocaties-bestaande-warmte-koude-opslag.zip"
[4] "http://financial-transactions-data-west-midlands-strategic-health-authority-October-2012"
[5] "http://Con la legge 18 giugno 2009, n. 69 è stato previsto, all’art. 21, che le pubbliche amministrazioni pubblichino sui rispettivi siti internet le retribuzioni annuali, i curricula vitae, gli indirizzi di posta elettronica e i numeri telefonici ad uso professionale dei dirigenti, nonché le statistiche sui tassi di assenza e di maggiore presenza del personale distinti per uffici di livello dirigenziale.  La Presidenza è quindi impegnata nella necessaria raccolta dei dati trattati dai diversi Uffici del Segretariato generale e dei Ministri senza portafoglio, anche al fine di assicurarne l’omogeneità indispensabile per poter presentare elaborazioni attendibili e significative di una realtà complessa ed articolata come quella della Presidenza del Consiglio. "
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Many of the links were specified as relative URLs, and I didn’t try to parse them.
I could have known to look for this, but having absolute URLs would still have
been easier.&lt;/p&gt;

&lt;p&gt;Also, some of the URLs were intranet file paths (like &lt;code&gt;S:Foo\Bar\Baz.xls&lt;/code&gt;).
Not all datasets are public yet, so this is better than nothing.
That said, I wonder whether people realize that these intranet paths are not
accessible on the normal internet.&lt;/p&gt;

&lt;h3 id="low-timeout"&gt;Low Timeout&lt;/h3&gt;
&lt;p&gt;Aside from the invalid URLs, most of the bad links gave a timeout.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_errors_total.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;As we saw above, different websites (hostnames) tend to give different errors.
The following plot should make it more clear.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_hostname_facet.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;Recall that people thought that CKAN doesn’t respond to HEAD requests. It might
just be that CKAN is slow to respond to requests. Here is a plot with datasets
color-coded based on whether they appear to be served from a CKAN FileStore.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/storage.png" alt="plot of chunk storage" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;(The &lt;code&gt;/storage&lt;/code&gt; endpoint is typically used for the CKAN FileStore.)&lt;/p&gt;

&lt;p&gt;It looks like the CKAN FileStore can take a while to respond, and that might be
why people thought that HEAD requests fail.&lt;/p&gt;

&lt;h2 id="duplicate-data"&gt;Duplicate data&lt;/h2&gt;
&lt;p&gt;It turned out that I had duplicate records in my table of link information. As I was working
with it, I forgot the correct schema and remembered a different one; I thought I had a unique
index on something for which I didn’t.&lt;/p&gt;

&lt;p&gt;To illustrate this, see below a plot of the number of CKAN datasets for which my link liveliness
data has duplicate records. The top bar graph is for datasets that were stored internally, and
the bottom bar graph is for datasets that were stored externally.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_duplicates_ckan.png" alt="plot of chunk p_duplicates_ckan" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;We see that there were quite a many duplicates, particularly for datasets that were stored
externally. This happened because I ran my downloader script multiple times, thinking that
duplicates were being skipped rather than resolved properly.&lt;/p&gt;

&lt;p&gt;Because of how I set up the database, it’s hard to see this in the Socrata data.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
## stat_bin: binwidth defaulted to range/30. Use 'binwidth = x' to adjust
## this. stat_bin: binwidth defaulted to range/30. Use 'binwidth = x' to
## adjust this.
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_duplicates_socrata.png" alt="plot of chunk p_duplicates_socrata" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;This plot shows that I have hundreds of duplicates of the same dataset.
Most of these duplicates probably came from original Socrata site (as explained
&lt;a href="/!/socrata-deduplicate"&gt;here&lt;/a&gt;).
Like with the CKAN datasets, my database schema issue probably only doubled or
tripled the duplication for the Socrata datasets.&lt;/p&gt;

&lt;h2 id="new-results"&gt;New results&lt;/h2&gt;
&lt;p&gt;I used a longer timeout on the previously-erring links and deduplicated my duplicates.
Here are new results that correspond with the plots in the
&lt;a href="/!/data-catalog-dead-links"&gt;previous article&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In these plots, each bar represents all of the datasets for one data catalog. The bar
is colored differently at different segments to represent different categories of dataset.&lt;/p&gt;

&lt;p&gt;The first plot shows that most datasets within a given catalog are alive, either because
they are internally stored or because they are stored externally and have live links.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_link_types.png" alt="plot of chunk p_link_types" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;Let’s ignore the datasets that are stored internally. The bars will represent only the
datasets that are external links, and the missing bars correspond to catalogs with no
external links.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_link_types_onlylinks.png" alt="plot of chunk p_link_types_onlylinks" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;One of my main conclusions in the prior article was that Socrata and CKAN encourage
different paradigms for adding data to the catalog. Socrata sites are more likely to
have internally stored data, and CKAN sites are more likely to have externally stored
data. On the other hand, externally stored datasets are more likely to be alive in
CKAN sites than in Socrata sites. I made this plot to explain that.&lt;/p&gt;

&lt;p&gt;&lt;img src="/!/data-catalog-dead-links/figure/prop_links.png" alt="Old version of the plot" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;The plot looks a bit different with the fixed data (below),&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_prop_links.png" alt="plot of chunk p_prop_links" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;but conclusion still seems reasonable.&lt;/p&gt;

&lt;h2 id="unexplained"&gt;Unexplained&lt;/h2&gt;
&lt;p&gt;Let’s look closely at the two catalogs for which my prior results didn’t seem right.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_link_types_specifics.png" alt="plot of chunk p_link_types_specifics" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;OpenVA is looking more alive than it did before, and the links that I marked as dead
are links with SSL problems. But I don’t know why Trentino’s links are marked as dead.
I checked a few of these links, and they download just fine.&lt;/p&gt;

&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;My prior article gave some strange figures regarding the liveliness of datasets.
In particular, there were high rates of dead links for some catalogs.
Most of the strange figures in my prior article are explained by me having duplicates
in my database. Also, some dead links are explained by factors that we might not think
of as dead links, such as ambigous URLs or bad SSL configurations.&lt;/p&gt;

&lt;p&gt;My main conclusion in the previous article is that CKAN and Socrata encourage storing
data in different places (internally and externally). After I accounted for the
duplication, this conclusion continues to seem valid.&lt;/p&gt;

&lt;p&gt;Finally, we saw some interesting issues with the construction of URLs for datasets.
There was a bit more variation in URLs than I had anticipated.&lt;/p&gt;

&lt;h1 id="appendix-how-i-figured-this-all-out"&gt;Appendix: How I figured this all out&lt;/h1&gt;
&lt;p&gt;Here are a bunch of things I tried doing in order to figure out what was going on.
It’s not very well organized or explained, but you might find it interesting.&lt;/p&gt;

&lt;h2 id="status-codes"&gt;Status codes&lt;/h2&gt;
&lt;p&gt;I called a URL alive if an ordinary HEAD request to it returned a
&lt;a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html"&gt;status code&lt;/a&gt; of 200.
This simplifies things a little bit.
I started out by considering whether this was an appropriate test.&lt;/p&gt;

&lt;p&gt;Here are all of the status codes that I received, from all of the different
links from all of the catalogs.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/status_codes.png" alt="plot of chunk status_codes" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;Let’s look at this for just the specific catalogs that those Tweets were about.
Here’s OpenVA.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/status_codes_va.png" alt="plot of chunk status_codes_va" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;And here’s Trentino.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/status_codes_trentino.png" alt="plot of chunk status_codes_trentino" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;Aside from 200, all of those status codes are errors, so this method of checking
seems fine. On the other hand, it seems like there were a lot of non-responses….
More about non-responses later; for now, we’ll just say that the status code
check is fine.&lt;/p&gt;

&lt;h2 id="duplicates"&gt;Duplicates&lt;/h2&gt;
&lt;p&gt;When plotting this, I realized that some of the data didn’t line up. I set up
a database schema that was more normalized so that I wouldn’t check a link twice
if two datasets linked to it. I thus had a datasets table and a links table.&lt;/p&gt;

&lt;p&gt;Then I wound up changing my mind and using the links table to store a single record
per dataset. Here arose a problem; there was no unique index on this datasets table,
but I thought there was, so I added multiple records for each link.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style="text-align: left"&gt;catalog&lt;/th&gt;
      &lt;th style="text-align: left"&gt;identifier&lt;/th&gt;
      &lt;th style="text-align: right"&gt;count(*)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_excavation_data&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_geophysics_cmdminiexplorer&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_geophysics_flashres64&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_geophysics_geoscanrm15&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_laboratorydata&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_monitoring_apparent_permitivity_cstdr100&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_monitoring_bulk_electrical_conductivity_cstdr100&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_monitoring_soilconductivity_imko_pico_t3p&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_monitoring_temperature_cs107l&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;dartportal.leeds.ac.uk&lt;/td&gt;
      &lt;td style="text-align: left"&gt;dart_monitoring_weather_data&lt;/td&gt;
      &lt;td style="text-align: right"&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I had thought that there was a unique index on
&lt;code&gt;links.software, links.catalog, links.identifier&lt;/code&gt;,
but there wasn’t!&lt;/p&gt;

&lt;h2 id="misinterpreting-nulls"&gt;Misinterpreting NULLs&lt;/h2&gt;
&lt;p&gt;Another issue: I had interpreted NULL as meaning that the dataset is not a link,
but it really represents that link’s liveliness has yet  to be checked;
here’s the relevant line of code.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;url_list = [row['url'] for row in dt.execute('SELECT DISTINCT url FROM links WHERE status_code IS NULL')]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I don’t remember exactly how this affected the results thought; it might not have
been a big deal.&lt;/p&gt;

&lt;h2 id="unresponsive-datasets"&gt;Unresponsive datasets&lt;/h2&gt;
&lt;p&gt;I recorded when HTTP requests for datasets had timed out or otherwise
not responded. (In the database, these are indicated as status code -42.)
I checked a few of these manually. Here are two of them.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dati.trentino.it/storage/f/2013-06-16T111814/_ggeiWE.csv
https://www-genesis.destatis.de/genesis/online/link/tabelleDownload/46421-0001.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;They both work, but they take a while. Also, I found that they took longer
to download to my desktop computer on my desk than they took to download to
my server in a datacenter.
In case the problem was my internet connection (tethered from a phone),
I used that server in a datacenter to run the checker again on
all datasets that had timed out. Results didn’t remarkably change.&lt;/p&gt;

&lt;h2 id="slow-datasets"&gt;Slow datasets&lt;/h2&gt;
&lt;p&gt;Those links took a while to download. Maybe my timeout threshold is being hit?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;url = 'http://dati.trentino.it/storage/f/2013-06-16T114537/_EBmYVk.csv'
import requests

timeout = requests.head(url, timeout = 2)
# timeout error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So it is. More detail follows.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;get = requests.get(url)
head = requests.head(url)

print(get)
# &amp;lt;Response [200]&amp;gt;

print(head)
# &amp;lt;Response [200]&amp;gt;

print(head.elapsed)
# datetime.timedelta(0, 3, 353558)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The link is alive, but my timeout of 2 seconds was too short.
In this case, the request with a timeout failed, so the initial
response took too long. Also, it took a total of 3.35 seconds to
download. The elapsed time isn’t the same thing as the time until
which the request will time out, but they’re related.&lt;/p&gt;

&lt;h3 id="bad-urls"&gt;Bad URLs&lt;/h3&gt;
&lt;p&gt;A bunch of datasets have a field for an external link but provided
an empty URL.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[1] catalog  count(*)
&amp;lt;0 rows&amp;gt; (or 0-length row.names)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Aside from being interesting in itself, this pointed out to me that
there were probably lots of types of errors that I hadn’t really
thought about. I realized I could look at the errors for each of the links
I checked. I thought I had saved the error in the database, but
my code for doing that turned out to be broken.&lt;/p&gt;

&lt;p&gt;So I fixed that! Collecting better error information, I ran the checker
on all of the links that had failed before.&lt;/p&gt;

&lt;h3 id="hostname"&gt;Hostname&lt;/h3&gt;
&lt;p&gt;I figured that errors might be related to the server that a dataset comes
from, and I figured that the hostname of the URL would be a decent proxy
for server. (In the URL “http://thomaslevine.com/open-data”, the hostname
is “thomaslevine.com”.) So I wrote a sloppy function to detect these hostnames.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  datasets$hostname &amp;lt;- sub('(?:(?:http|ftp|https)://)?([^/]*)/.*$', '\\1', datasets$url)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here are the top few hostnames and the number of datasets with each hostname.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;              \t 0ccfs001.sussex.nhs.uk\\csu
               1                           1
10.96.9.105:8080               176.32.230.19
               1                           1
 192.171.153.213               194.151.67.33
               1                           1
   195.217.160.2              195.55.247.252
               1                           1
 2010.census.gov              207.251.86.229
               1                           1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Having come up with this variable, I now could look at error types by hostname.&lt;/p&gt;

&lt;h3 id="base-error-rate"&gt;Base error rate&lt;/h3&gt;
&lt;p&gt;&lt;img src="figure/p_errors_total.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_hostname_total.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_hostname_error.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_hostname_facet.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;h3 id="invalid-urls"&gt;Invalid URLs&lt;/h3&gt;
&lt;p&gt;The “http:” datasets weren’t valid URLs.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Error type&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;ConnectionError&lt;/td&gt;
      &lt;td&gt;http:// Localisation des accès des offices de tourisme&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ConnectionError&lt;/td&gt;
      &lt;td&gt;http://nullFPM.shp.zip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ConnectionError&lt;/td&gt;
      &lt;td&gt;http:// 2012_PNOA.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ConnectionError&lt;/td&gt;
      &lt;td&gt;http://fotovoltaico.provincia.tn.it\solar.xml&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LocationParseError&lt;/td&gt;
      &lt;td&gt;http://2011 NFL draft: Andrew Luck is cementing his status as the No. 1 overall prospect on the board.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id="connection-errors"&gt;Connection errors&lt;/h3&gt;
&lt;p&gt;Connection errors seem to correspond to some datasets with strange URLs and others for
which the site just can’t be contacted.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/connectionerror.png" alt="plot of chunk connectionerror" class="wide" /&gt;&lt;/p&gt;

&lt;h3 id="invalid-schemas"&gt;Invalid schemas&lt;/h3&gt;
&lt;p&gt;Invalid schemas are for datasets sent over protocals other than HTTP, like FTP.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/invalidschema.png" alt="plot of chunk invalidschema" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;Most of these schemas indicate that the files are stored on local systems
rather than being accessible from the internet. But a large minority of these
(FTP, specifically) is fully reasonable to put on the internet; I didn’t
check them properly.&lt;/p&gt;

&lt;h3 id="missing-schemas"&gt;Missing schemas&lt;/h3&gt;
&lt;p&gt;Missing schemas tend to be for datasets where the hostname was not specified.
Examples:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[1] "/storage/f/2012-08-13T002240/COSCParks.kmz"
[2] "/storage/f/2012-08-22T025312/prod_test.csv"
[3] "/storage/f/2012-08-10T100153/sc_addies.csv"
[4] "/en/storage/f/2013-02-11T170442/Copy-of-GB_Certified_130211_for-map.csv"
[5] "/storage/f/2012-08-10T071459/annual-new-h2o-meters-2000-2010.csv"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="figure/missingschema.png" alt="plot of chunk missingschema" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;This is a valid relative URL. I could have gotten the hostname from the site
from which I got the link, but I did not do this.&lt;/p&gt;

&lt;h3 id="ssl-errors"&gt;SSL Errors&lt;/h3&gt;
&lt;p&gt;A bunch of sites did not have SSL certificates that I recognized.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_ssl_error.png" alt="plot of chunk p_ssl_error" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;I could ignore the certificates and download the dataset, but the SSL warning
is slightly unnerving.&lt;/p&gt;

&lt;p&gt;SSL errors explain only a small part of the links I marked as dead. Of the
datasets that I’d marked as dead before, 457 had SSL errors and 7630 did not.&lt;/p&gt;

&lt;p&gt;They are interesting, but they don’t explain my strange results.&lt;/p&gt;

&lt;h3 id="timeouts"&gt;Timeouts&lt;/h3&gt;
&lt;p&gt;Once we get rid of the strange URLs, most of these links have no errors or have
timeouts. (Remember, these are the links that I marked as dead in my previous
analysis, and I tried downloading again for the present analysis.)&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_hostname_facet.png" alt="" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;The “www-genesis.destatis.de” datasets seem mostly okay, though there are some timeouts.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/plot_destatis.png" alt="plot of chunk plot_destatis" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/p_elapsed.png" alt="plot of chunk p_elapsed" class="wide" /&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2014-02-21:/!/decompilers-in-css/index.html</id>
    <title type="html">Decompilers in CSS</title>
    <published>2014-02-21T00:00:00Z</published>
    <updated>2014-02-21T00:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/decompilers-in-css/index.html"/>
    <content type="html">&lt;p&gt;I wrote
&lt;a href="https://github.com/tlevine/csv.css"&gt;CSV&lt;/a&gt;,
&lt;a href="http://openprism.thomaslevine.com/"&gt;markdown&lt;/a&gt;, and
&lt;a href="https://github.com/tlevine/html2tex"&gt;LaTeX&lt;/a&gt;
decompilers in CSS.&lt;/p&gt;

&lt;p&gt;And now the tables on thomaslevine.com are styled as CSVs!&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;column1&lt;/th&gt;
      &lt;th&gt;column2&lt;/th&gt;
      &lt;th&gt;column3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2014-02-03:/!/open-data-500-data-package/index.html</id>
    <title type="html">Open Data 500 Data Package</title>
    <published>2014-02-03T00:00:00Z</published>
    <updated>2014-02-03T00:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/open-data-500-data-package/index.html"/>
    <content type="html">&lt;p&gt;I recently took a stab at documenting the
&lt;a href="http://www.opendata500.com"&gt;Open Data 500&lt;/a&gt; data format,
but my &lt;a href="/!/open-data-500-data-dictionary"&gt;work thus far&lt;/a&gt;
leaves much to be desired. I looked at it a bit more over the weekend,
and I think I have a pretty good idea about it now.
Collecting all of my findings about the data format,
I packaged the data in a way that should be a bit easier to work with.&lt;/p&gt;

&lt;h2 id="more-stuff-i-figured-out-about-the-open-data-500-data"&gt;More stuff I figured out about the Open Data 500 data&lt;/h2&gt;
&lt;p&gt;It was pretty simple to convert the data formats once I figured them out, but
that step took me a while. The main issue was reconciling the conflicting data
that are reported on the Open Data 500 site.&lt;/p&gt;

&lt;h3 id="the-conflicting-data"&gt;The conflicting data&lt;/h3&gt;
&lt;p&gt;The Open Data 500 Team released four data files in its “Downloads” section,
and it implicitly released two HTML data files elsewhere on its site.
Some of these seem to present the same data in different formats, but when
I looked closely, I found that they actually contained different data, and
I wasn’t really sure which data to use. Do I combine the different files?
If a company is in one file but not another, is it part of the study?
Is one of the files more up-to-date?&lt;/p&gt;

&lt;p&gt;I never really figured out what to do about all this.&lt;/p&gt;

&lt;h3 id="all-questionnaire-responses-will-be-included"&gt;All questionnaire responses will be included&lt;/h3&gt;
&lt;p&gt;Until I did last week’s research into the Open Data 500 methodology,
I had the impression that the Open Data 500 involved some assessment of
companies beyond what they say in the questionnaire. Now, I think that
the study is just an ordinary questionnaire survey and that they want as
many responses as they can get. If this is the case, the Open Data 500 Team
would probably want to report any company that completed the questionnaire.&lt;/p&gt;

&lt;p&gt;In assembling my Open Data 500 dataset, I thus think it’s safe to include
any company that was included in any of the official Open Data 500 dataset
releases.&lt;/p&gt;

&lt;h3 id="only-the-html-version-gets-updated"&gt;Only the HTML version gets updated&lt;/h3&gt;
&lt;p&gt;The CSV and JSON versions of the larger Open Data 500 list include
51 companies each, and the HTML version of the larger Open Data 500 list
includes 100 companies. I wasn’t really sure what to make of this, but now
I have a guess.&lt;/p&gt;

&lt;p&gt;I scraped the data from the various HTML pages on the site, and I noticed
that there is indeed quite complete data for all of these 100 companies.
I thus think that these companies responded to the questionnaire.&lt;/p&gt;

&lt;p&gt;Also, I noticed that the “download” section isn’t being updated.
I downloaded the JSON and CSV files in this section when they
were first released in December, and they files on the website
haven’t changed since.&lt;/p&gt;

&lt;p&gt;I haven’t been downloading the HTML files regularly, but it looks like the
site is being updated.
I found &lt;a href="https://github.com/GovLab/OpenData500"&gt;this code repository&lt;/a&gt;,
which seems to be the code for the site. In that repository as well,
the “download” files have never been updated. But recent development on
the site has been happening, so I find it conceivable that the data behind
the HTML files is being updated. The data are being stored in Mongo rather
than as files in the repository, so I can’t say for sure that the data are
being updated, but it seems likely.&lt;/p&gt;

&lt;p&gt;Anyway, my broader conclusion is that the HTML pages &lt;strong&gt;are&lt;/strong&gt; being updated and
the “download” section &lt;strong&gt;is not&lt;/strong&gt; being updated.&lt;/p&gt;

&lt;h2 id="packaging-the-data"&gt;Packaging the data&lt;/h2&gt;
&lt;p&gt;I produced two different CSV file to describe the same data, and these file
should make a lot more sense than the official CSV files. One of the files,
&lt;code&gt;companies.csv&lt;/code&gt;, has a row for every company and is normalized. The other,
&lt;code&gt;datasets.csv&lt;/code&gt;, has a row for every dataset, with different rows duplicating
the data about the companies; it is denormalized and contains no data about
the companies that lack datasets.&lt;/p&gt;

&lt;h3 id="upstream-sources"&gt;Upstream sources&lt;/h3&gt;
&lt;p&gt;The data come from the “full list” section of the Open Data 500 website.
I took most of the data for any particular company from its page on the website;
for example, most of the data for Appallicious came from
&lt;a href="http://www.opendata500.com/Appallicious/"&gt;&lt;code&gt;http://www.opendata500.com/Appallicious/&lt;/code&gt;&lt;/a&gt;.
I also took data from the &lt;a href="http://www.opendata500.com/candidates"&gt;full list page&lt;/a&gt;.
If the same field was present on both pages (for example, the company name),
I used the value on the company’s particular page rather than the value on the
main “full list” page.&lt;/p&gt;

&lt;h3 id="schema-of-the-companies-file"&gt;Schema of the companies file&lt;/h3&gt;
&lt;p&gt;This version of the dataset is a single CSV file,
where each row is a company and most columns
are answers to questionnaire questions. (I think! Remember that I’m guessing at
all of this.) Here are the columns that I think to come from the first page of
the questionnaire.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Column name&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;company.name&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Name of your company&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;`company.url&lt;/td&gt;
      &lt;td&gt;Company URL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;location&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;“In which city is this company located?”, and “State” (two questions)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;year.founded&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Founding Year&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;fte&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Number of FTE’s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;type.of.company&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Type of Company&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;category&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What category best describes your company?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;function&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which best describes the function of your company?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;source.of.revenue&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which of the following are significant sources of revenue for your company?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Please give us a short public statement describing your company’s mission and work. You can take this material from your website or other publications if you choose to.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;description.short&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;As a summary, please provide a one sentence description of your company.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;social.impact&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Besides revenue generation, how do you measure the impact your company has for society and the public good?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;financial.info&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Please include any financial or operational information that will help us understand your company. We are interested in specific information like past and projected annual revenues, total outside investment dollars to date, and significant investors or partners.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code&gt;dataset&lt;/code&gt; field contains a CSV file of the datasets listed on subsequent
pages of the questionnaire. This file has a row for each dataset, and it has
columns for the URL (&lt;code&gt;dataset.url&lt;/code&gt;) and name (&lt;code&gt;dataset.name&lt;/code&gt;) of the dataset.&lt;/p&gt;

&lt;p&gt;The three remaining fields are not from the questionnaire&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Column name&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;company.href&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Location of the company page within the Open Data 500 website&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;data.collection&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which method was used for data collection? (“questionnaire” or “undocumented”)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;And I suspect that the &lt;code&gt;sectors(s)&lt;/code&gt; column comes from the questionnaire,
but I haven’t figured out what question it’s from.&lt;/p&gt;

&lt;h3 id="schema-of-the-datasets-file"&gt;Schema of the datasets file&lt;/h3&gt;
&lt;p&gt;In the datasets file, each row is a dataset used by a company.
The datasets file contains all of the columns that are in the companies
file except for the &lt;code&gt;datasets&lt;/code&gt; column, and it adds two more columns:
&lt;code&gt;dataset.url&lt;/code&gt; for the link to the dataset, and &lt;code&gt;dataset.name&lt;/code&gt; for the
name of the dataset. These are the two columns inside the nested CSV
files in the companies file.&lt;/p&gt;

&lt;p&gt;Because each row is about a dataset, this file contains no data about
companies with zero datasets.&lt;/p&gt;

&lt;h3 id="questionnaire-versus-undocumented-data-collection"&gt;Questionnaire versus undocumented data collection&lt;/h3&gt;
&lt;p&gt;I separate the data collection methods for the Open Data 500 into two methods.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Convenience-sampled questionnaire responses
 (“&lt;a href="#comprehensive-call-sampling-strategy"&gt;comprehensive call&lt;/a&gt;”)&lt;/li&gt;
  &lt;li&gt;Undocumented data collection&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Data from both sorts of data collection are included in the companies dataset,
and the &lt;code&gt;data.collection&lt;/code&gt; field indicates which method was used.
You’ll also notice that much of the data are missing for rows that were
collected with the undocumented method.&lt;/p&gt;

&lt;p&gt;The datasets file, on the other hand, contains no data about companies that
were collected through the undocumented method; in the undocumented data
collection method, no data were produced about datasets used by the companies.&lt;/p&gt;

&lt;h2 id="using-the-data"&gt;Using the data&lt;/h2&gt;
&lt;p&gt;You can download the files here.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://raw.github.com/tlevine/open-data-500/master/companies.csv"&gt;&lt;code&gt;companies.csv&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://raw.github.com/tlevine/open-data-500/master/datasets.csv"&gt;&lt;code&gt;datasets.csv&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I’ve also packaged the it as a
&lt;a href="http://data.okfn.org/standards/data-package"&gt;Data Package&lt;/a&gt;,
so you can check out the git repository 
(&lt;code&gt;git://github.com/tlevine/open-data-500.git&lt;/code&gt;)
and use any of
&lt;a href="http://data.okfn.org/tools"&gt;these fancy tools&lt;/a&gt;
to load the &lt;code&gt;datapackage.json&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Do tell me if you have any trouble with the files.
And I’d love to hear about
anything that you find with the data!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2014-01-31:/!/open-data-500-data-dictionary/index.html</id>
    <title type="html">A data dictionary of the Open Data 500 data</title>
    <published>2014-01-31T00:00:00Z</published>
    <updated>2014-01-31T00:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/open-data-500-data-dictionary/index.html"/>
    <content type="html">&lt;p&gt;The &lt;a href="http://www.opendata500.com/download/"&gt;Open Data 500&lt;/a&gt; is
“the first comprehensive study of U.S. companies using open government data to develop new products and services.”
You may have read about it in.
&lt;a href="http://www.forbes.com/sites/bethsimonenoveck/2014/01/08/from-faith-based-to-evidence-based-the-open-data-500-and-understanding-how-open-data-helps-the-american-economy/"&gt;Forbes&lt;/a&gt;,
&lt;a href="http://www.informationweek.com/government/open-government/open-government-data-companies-cash-in/d/d-id/1113143"&gt;Information Week&lt;/a&gt;, or
&lt;a href="http://fedscoop.com/open-data-500-intersection-open-data-economy/"&gt;Fedscoop&lt;/a&gt;
This is &lt;a href="/open-data"&gt;data about open data&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;The Open Data 500 Team doesn’t provide a data dictionary, so I pieced one
together for my own purposes. And I figured somebody else might want it for
her own purposes, so here it is. The present article discusses&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What the Open Data 500 is, in terms of research methods&lt;/li&gt;
  &lt;li&gt;How the released data files are structured&lt;/li&gt;
  &lt;li&gt;Clarification of some possible points of confusion&lt;/li&gt;
  &lt;li&gt;Recommendations as to how to work with the data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This article has more detail than most people will want, so
&lt;a href="#key-points-and-recommendations"&gt;jump to the summary&lt;/a&gt; if you like.&lt;/p&gt;

&lt;h2 id="data-collection-methods"&gt;Data collection methods&lt;/h2&gt;
&lt;p&gt;The Open Data 500 looks a bit scary and complicated when you read its website
and the articles about it, but the Open Data 500 is pretty much just a
straightforward questionnaire survey.&lt;/p&gt;

&lt;h3 id="the-population-of-interest"&gt;The population of interest&lt;/h3&gt;
&lt;p&gt;The Open Data 500 Team is interested in companies that meet their
&lt;a href="http://www.opendata500.com/about/#about-eligibility"&gt;eligibility criteria&lt;/a&gt;,
which they describe as follows.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Be U.S.-based – which can include international companies with a major presence in the U.S.&lt;/li&gt;
  &lt;li&gt;Earn revenue from its products and services. In addition to for-profit companies, nonprofits may qualify if they support themselves primarily through sales of products and services rather than philanthropy.&lt;/li&gt;
  &lt;li&gt;Use open government data as a critical resource for its business. (While most Open Data 500 companies will work with federal data, the study will also include some that use city or state data if their work can scale regionally or nationally)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The Open Data 500 site does not explain how they operationalize these criteria,
but I presume that it works as follows.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The questionnaire must indicate that a company has a major presence in the U.S.&lt;/li&gt;
  &lt;li&gt;The answer to “Which of the following are significant sources of revenue for your company?”
  must include something other than “Philanthropy”.&lt;/li&gt;
  &lt;li&gt;The answer to “Which of the following are critical sources of data for your company?”
  must include “Federal Open Data”, the questionnaire must indicate elsewhere that
  the company is using state or city data from a range of states or cities.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;They are “&lt;a href="http://www.opendata500.com/about/#about-vetted"&gt;vetting&lt;/a&gt;” companies,
but this sounds like just a conversation with the submitters to check that they
understood the questionnaire properly.&lt;/p&gt;

&lt;h3 id="comprehensive-call-sampling-strategy"&gt;Comprehensive call sampling strategy&lt;/h3&gt;
&lt;p&gt;The Open Data 500 uses a sampling strategy that they term “comprehensive call”.
That sounds really complicated, but it’s actually quite simple.&lt;/p&gt;

&lt;p&gt;The questionnaire results can be considered a 
&lt;a href="http://en.wikipedia.org/wiki/Accidental_sampling"&gt;convenience sample&lt;/a&gt;
of companies that meet the Open Data 500 eligibility criteria.&lt;/p&gt;

&lt;p&gt;The Open Data 500 Team distributed links to the questionnaire in
&lt;a href="http://www.opendata500.com/about/#about-identify"&gt;these places&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Recommendations from government and non-governmental organizations studying this field.&lt;/li&gt;
    &lt;li&gt;List of companies using datasets from Data.gov, the federal hub for government data&lt;/li&gt;
    &lt;li&gt;Online Open Data Userbase created by Socrata&lt;/li&gt;
    &lt;li&gt;Directory of open data companies developed by Deloitte&lt;/li&gt;
    &lt;li&gt;Mass email to 3100 people in the GovLab network&lt;/li&gt;
    &lt;li&gt;Mass email to 2200 people on contact list for OpenDataNow.com, website of Open Data 500 project director Joel Gurin&lt;/li&gt;
    &lt;li&gt;Companies identified in research for upcoming book, Open Data Now&lt;/li&gt;
    &lt;li&gt;Response to coverage of the Open Data 500 in Information Week and FedScoop&lt;/li&gt;
    &lt;li&gt;Outreach through Twitter&lt;/li&gt;
    &lt;li&gt;Outreach at “Data Transparency 2013” conference (September 2013, Washington, DC)&lt;/li&gt;
    &lt;li&gt;Blog posts on TheGovLab.org and OpenDataNow.com&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;That’s all that “comprehensive call” means!&lt;/p&gt;

&lt;p&gt;I think their use of comprehensive call is why the Open Data 500 Team considers
the Open Data 500 to be a comprehensive study.&lt;/p&gt;

&lt;h3 id="undocumented-data-collection"&gt;Undocumented data collection&lt;/h3&gt;
&lt;p&gt;Open Data 500 Team solicited responses to
&lt;a href="http://www.opendata500.com/submitCompany/"&gt;this questionnaire&lt;/a&gt; through
&lt;a href="#comprehensive-call-sampling-strategy"&gt;comprehensive call&lt;/a&gt;,
 but they also looked for companies
that did not respond to the questionnaire.&lt;/p&gt;

&lt;p&gt;I couldn’t find any documentation about the process they went through for
collecting data without the questionnaire. After talking to one of the Team
members, I think that the Team collected data about these companies without
talking directly to anyone who works there, but I do not know how they chose
the companies nor how they collected the data.&lt;/p&gt;

&lt;h3 id="case-study"&gt;Case study&lt;/h3&gt;
&lt;p&gt;In both the questionnaire section of the study and in the undocumented data
collection, only companies that meet the eligibility criteria are considered.
Thus, the Open Data 500 is a &lt;a href="http://en.wikipedia.org/wiki/Case_study"&gt;case study&lt;/a&gt;
of companies that meet the Open Data 500 eligibility criteria; there is not
a control group of companies that do not meet the criteria.&lt;/p&gt;

&lt;h2 id="just-a-questionnaire"&gt;Just a questionnaire&lt;/h2&gt;
&lt;p&gt;Aside from the undocumented data collection, which produces only coarse information,
the data collection for the Open Data 500 is just the questionnaire.
&lt;strong&gt;Really&lt;/strong&gt;. (This is the main thing that confused me.)&lt;/p&gt;

&lt;p&gt;For example, the Team isn’t looking at companies products to see which open data
are used, and it isn’t looking at annual reports to determine whether the
company does a lot of business in the United States.&lt;/p&gt;

&lt;h2 id="sample-size"&gt;Sample size&lt;/h2&gt;
&lt;p&gt;It is unclear to me how many companies responded to the questionnaire, but I
think it is either 51 companies or
100 companies.
I explain this more in the
&lt;a href="#which-companies-are-in-the-preview?"&gt;Which companies are in the preview?&lt;/a&gt;
section.&lt;/p&gt;

&lt;h2 id="pre-launch"&gt;Pre-launch&lt;/h2&gt;
&lt;p&gt;According to the “&lt;a href="http://www.opendata500.com/about"&gt;About&lt;/a&gt;” page on the
Open Data 500 site, the Open Data 500 “will identify, describe, and analyze
companies that use open government data in their businesses.”&lt;/p&gt;

&lt;p&gt;As I understand it, the analysis component of this has yet to occur.
At the moment, the Open Data 500 is in “pre-launch”. This means that they have
begun to collect data but that they haven’t done any sort of analysis on it.
(This part isn’t explained on the website, but a member of the Open Data 500
Team explained this to me in person.)&lt;/p&gt;

&lt;h2 id="data-files"&gt;Data files&lt;/h2&gt;
&lt;p&gt;The Open Data 500 Team has released six main data files.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://www.opendata500.com/download/Preview50_Companies.csv"&gt;&lt;code&gt;Preview50_Companies.csv&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://www.opendata500.com/download/500_Companies.csv"&gt;&lt;code&gt;500_Companies.csv&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://www.opendata500.com/download/OD500_Companies.json"&gt;&lt;code&gt;OD500_Companies.json&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://www.opendata500.com/download/OD500_Datasets.json"&gt;&lt;code&gt;OD500_Datasets.json&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://www.opendata500.com/preview/"&gt;&lt;code&gt;preview&lt;/code&gt;&lt;/a&gt; (HTML)&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://www.opendata500.com/candidates/"&gt;&lt;code&gt;candidates&lt;/code&gt;&lt;/a&gt; (HTML)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are also individual pages about each company, but I’m pretty sure that
the only extra information on those is comments submitted through the comment
forms.&lt;/p&gt;

&lt;h3 id="preview50companiescsv"&gt;Preview50_Companies.csv&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.opendata500.com/download/Preview50_Companies.csv"&gt;&lt;code&gt;Preview50_Companies.csv&lt;/code&gt;&lt;/a&gt;
is a denormalized CSV file with
25 columns and 102 rows.
Each row corresponds to a dataset within a company, and
each column corresponds to a question from the
&lt;a href="http://www.opendata500.com/submitCompany/"&gt;questionnaire&lt;/a&gt;.
51 different companies are
represented in this dataset.&lt;/p&gt;

&lt;p&gt;The column names in this file correspond quite closely to the name
attributes in the HTML form source code for the questionnaire.&lt;/p&gt;

&lt;p&gt;These columns describe the companies, and they are identical across different
rows about the same company. &lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code in the file&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;CompanyName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Name of your company&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;URL&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Company URL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;city&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;In which city is this company located?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;STATE&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;State [1]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;abbrev&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;State [1]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;zipCode&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Zip Code&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;ceoFirstName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;First Name of CEO&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;ceoLastName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Last Name of CEO&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyPreviousName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;???&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;yearFounded&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Founding Year&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;FTE&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Number of FTE’s [2]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyType&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Type of Company (Data management and analysis, Nonprofit, Private, Public) [3]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyCategory&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What category best describes your company? (Business &amp;amp; Legal Services, Data/Technology, Education, Energy, Environment &amp;amp; Weather, Finance &amp;amp; Investment, Food &amp;amp; Agriculture, Geospatial/Mapping, Governance, Healthcare, Housing/Real Estate, Lifestyle &amp;amp; Consumer, Scientific Research) [1]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyFunction&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which best describes the function of your company? (many different levels) [3]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;sectors&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What category best describes your company? (many different levels) [1,3]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;revenueSource&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which of the following are significant sources of revenue for your company? [4]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;descriptionLong&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Please give us a short public statement describing your company’s mission and work. You can take this material from your website or other publications if you choose to.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;descriptionShort&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;As a summary, please provide a one sentence description of your company.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;socialImpact&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Besides revenue generation, how do you measure the impact your company has for society and the public good?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;financialInfo&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Please include any financial or operational information that will help us understand your company. We are interested in specific information like past and projected annual revenues, total outside investment dollars to date, and significant investors or partners.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;criticalDataTypes&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which of the following are critical sources of data for your company? By “critical,” we mean that your company would have to shut down a line of business, shut down completely, or replace the data in some way if the data were no longer available.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;It does not include the following questions from that first page of the questionnaire.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code from the web form&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;firstName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;First Name [5]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;lastName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Last Name&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Title&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;email&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Email&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;phone&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Phone&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;contacted&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Please check here if you would be willing to be contacted for further information about your company.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;datasetWishList&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What datasets (if any) are not currently available that would be useful for your company to have as government open data?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyRec&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What other companies, either in your sector or other sectors, would you recommend we contact regarding their use of government open data?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;conferenceRec&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What conferences or events do you think would be helpful to us in surveying the field of open data companies?&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The following columns come from the
&lt;a href="http://www.opendata500.com/addData/52eb5431def7fa00029abc8f/"&gt;“New Dataset”&lt;/a&gt;
page of the questionnaire.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code in the file&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;datasetName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Name of Dataset&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;datasetURL&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;URL of Dataset&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;agencyOrDatasetSource&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Agency or Source&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The file does not include the following columns from the “New Dataset” page.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code from the web form&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;typeOfDataset&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Type of Dataset (Federal Open Data, State Open Data, City/Local Open Data, Other)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;rating&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;On a scale of 1 to 4, how would you rate the usefulness of this dataset? (1- poor, 4- excellent) Your answer can reflect your experience with data quality, format of the data, or other factors.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;reason&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Why did you give it this rating?&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Finally, there is also a &lt;code&gt;DATASETS&lt;/code&gt; column, which is the number of datasets
submitted for the particular the company.&lt;/p&gt;

&lt;p&gt;You can think of this file as a CSV version of &lt;code&gt;OD500_Companies.json&lt;/code&gt;.&lt;/p&gt;

&lt;!-- all(unique(sort(preview.csv$CompanyName)) == sort(sapply(candidates.json, function(x){x$companyName}))) --&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;In some cases, answers to one question are presented redundantly across
 multiple columns.&lt;/li&gt;
  &lt;li&gt;“FTE” probably stands for “full-time equivalent employees”.&lt;/li&gt;
  &lt;li&gt;The questionnaire has different categories from the levels reported in
 this file.&lt;/li&gt;
  &lt;li&gt;This cell contains a comma-and-space (&lt;code&gt;, &lt;/code&gt;) delimited list of items,
 and I haven’t picked apart the lists to find all of the possible values
 in the list.&lt;/li&gt;
  &lt;li&gt;This is from the “Personal Information” section, which presumably
 describes the person who is filling out the questionnaire.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="companiescsv"&gt;500_Companies.csv&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.opendata500.com/download/500_Companies.csv"&gt;&lt;code&gt;500_Companies.csv&lt;/code&gt;&lt;/a&gt;
is a CSV file with
7 columns and 503 rows.
Each row corresponds to a unique company, and
each column corresponds to a question from the
&lt;a href="http://www.opendata500.com/submitCompany/"&gt;questionnaire&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code in the file&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;CompanyName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Name of your company&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;URL&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Company URL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;city&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;In which city is this company located?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;STATE&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;State&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;abbrev&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;State&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;zipCode&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Zip Code&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyCategory&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What category best describes your company? (Business &amp;amp; Legal Services, Data/Technology, Education, Energy, Environment &amp;amp; Weather, Finance &amp;amp; Investment, Food &amp;amp; Agriculture, Geospatial/Mapping, Governance, Healthcare, Housing/Real Estate, Lifestyle &amp;amp; Consumer, Scientific Research)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;descriptionShort&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;As a summary, please provide a one sentence description of your company.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This file provides no data about datasets used by the companies.&lt;/p&gt;

&lt;p&gt;Recall that the study includes both questionnaire data and data collected
by undocumented means. This file contains data collected by both methods.&lt;/p&gt;

&lt;h3 id="od500companiesjson"&gt;OD500_Companies.json&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.opendata500.com/download/OD500_Companies.json"&gt;&lt;code&gt;OD500_Companies.json&lt;/code&gt;&lt;/a&gt;
is a JSON file with an array of associative arrays (that is, a list of mappings).
It has 51 rows (associative ararys) and 
22 columns (items per associative array).
Each row corresponds to a unique company,
and each column corresponds to a questionnaire question.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code in the file&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Name of your company&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;url&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Company URL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;city&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;In which city is this company located?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;state&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;State [1]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;zipCode&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Zip Code&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;ceoFirstName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;First Name of CEO&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;ceoLastName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Last Name of CEO&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;previousName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;???&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;yearFounded&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Founding Year&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;fte&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Number of FTE’s [2]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyType&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Type of Company (Data management and analysis, Nonprofit, Private, Public) [3]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyCategory&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What category best describes your company? (Business &amp;amp; Legal Services, Data/Technology, Education, Energy, Environment &amp;amp; Weather, Finance &amp;amp; Investment, Food &amp;amp; Agriculture, Geospatial/Mapping, Governance, Healthcare, Housing/Real Estate, Lifestyle &amp;amp; Consumer, Scientific Research) [1]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyFunction&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which best describes the function of your company? (many different levels) [3]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;sector&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What category best describes your company? (many different levels) [1,3]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;revenueSource&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which of the following are significant sources of revenue for your company?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;descriptionLong&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Please give us a short public statement describing your company’s mission and work. You can take this material from your website or other publications if you choose to.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;descriptionShort&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;As a summary, please provide a one sentence description of your company.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;socialImpact&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Besides revenue generation, how do you measure the impact your company has for society and the public good?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;soccialInfo&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Please include any financial or operational information that will help us understand your company. We are interested in specific information like past and projected annual revenues, total outside investment dollars to date, and significant investors or partners.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;criticalDataTypes&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Which of the following are critical sources of data for your company? By “critical,” we mean that your company would have to shut down a line of business, shut down completely, or replace the data in some way if the data were no longer available.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- subset(preview.csv, CompanyName == 'BillGuard')[1,'financialInfo'] == preview.json[[3]]$socialInfo --&gt;

&lt;p&gt;It does not include the following questions from that first page of the questionnaire.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code from the web form&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;firstName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;First Name [4]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;lastName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Last Name&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Title&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;email&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Email&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;phone&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Phone&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;contacted&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Please check here if you would be willing to be contacted for further information about your company.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;datasetWishList&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What datasets (if any) are not currently available that would be useful for your company to have as government open data?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;companyRec&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What other companies, either in your sector or other sectors, would you recommend we contact regarding their use of government open data?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;conferenceRec&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;What conferences or events do you think would be helpful to us in surveying the field of open data companies?&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In addition to the 20 columns I describe above, there are two columns for
identificatiers. One is the &lt;code&gt;companyId&lt;/code&gt; column, which is the unique
identifier for the particular company. Within the questionnaire, this shows up
inside the URL for the
&lt;a href="http://www.opendata500.com/addData/52eb5431def7fa00029abc8f/"&gt;“New Dataset”&lt;/a&gt;
page.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://www.opendata500.com/addData/$companyId/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The other is the &lt;code&gt;datasets&lt;/code&gt; column, which lists identification codes
for datasets (like  151fe3724a03bb3b4c52ae10) and references the
&lt;code&gt;datasetID&lt;/code&gt; column in &lt;code&gt;OD500_Datasets.json&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You can think of this file as a JSON version of &lt;code&gt;Preview50_Companies.csv&lt;/code&gt;.&lt;/p&gt;

&lt;!-- all(unique(sort(preview.csv$CompanyName)) == sort(sapply(candidates.json, function(x){x$companyName}))) --&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;In some cases, answers to one question are presented redundantly across
 multiple columns.&lt;/li&gt;
  &lt;li&gt;“FTE” probably stands for “full-time equivalent employees”.&lt;/li&gt;
  &lt;li&gt;The questionnaire has different categories from the levels reported in
 this file.&lt;/li&gt;
  &lt;li&gt;This is from the “Personal Information” section, which presumably
 describes the person who is filling out the questionnaire.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="od500datasetsjson"&gt;OD500_Datasets.json&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.opendata500.com/download/OD500_Datasets.json"&gt;&lt;code&gt;OD500_Datasets.json&lt;/code&gt;&lt;/a&gt;
is a JSON file with an array of associative arrays (that is, a list of mappings).
It has 51 rows (associative ararys) and 
22 columns (items per associative array).
Each row corresponds to a dataset. Three of the columns correspond directly to
questionnaire questions.&lt;/p&gt;

&lt;p&gt;The following columns come from the
&lt;a href="http://www.opendata500.com/addData/52eb5431def7fa00029abc8f/"&gt;“New Dataset”&lt;/a&gt;
page of the questionnaire.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code in the file&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;datasetName&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Name of Dataset&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;datasetURL&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;URL of Dataset&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;source&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Agency or Source&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The file does not include the following columns from the “New Dataset” page.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Code from the web form&lt;/th&gt;
      &lt;th&gt;Question from the questionnaire&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;typeOfDataset&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Type of Dataset (Federal Open Data, State Open Data, City/Local Open Data, Other)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;rating&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;On a scale of 1 to 4, how would you rate the usefulness of this dataset? (1- poor, 4- excellent) Your answer can reflect your experience with data quality, format of the data, or other factors.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;reason&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Why did you give it this rating?&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The file also contains two identifier columns. identificatiers.
One is the &lt;code&gt;datasetID&lt;/code&gt; column, which serves as a primary key for this table.
The other is the &lt;code&gt;usedByCompany&lt;/code&gt; column, which references the &lt;code&gt;companyId&lt;/code&gt;
in &lt;code&gt;OD500_Companies.json&lt;/code&gt;,&lt;/p&gt;

&lt;h3 id="preview-html"&gt;preview (HTML)&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.opendata500.com/preview/"&gt;&lt;code&gt;preview&lt;/code&gt;&lt;/a&gt; is an HTML page
containing a non-standard representation of a data table about companies.&lt;/p&gt;

&lt;p&gt;The companies are represented as a nodes with the following XPath.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[1] "//ul[@class=\"m-preview-list\"]/li[@class=\"m-list-company\"]"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The file contains 51 companies and about 11 fields
(depending on your definition of a field). The fields are approximately
a subset of the fields for &lt;code&gt;Preview50_Companies.csv&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I don’t feel like writing out selectors for every field within each company
node, but you can figure it out by looking at the code for the first company.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;li class="m-list-company"&amp;gt;
&amp;lt;div class="m-list-company-summary"&amp;gt;
&amp;lt;div class="m-preview-list-control"&amp;gt;&amp;lt;span class="m-expand-arrow"/&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;div class="m-preview-list-name"&amp;gt;&amp;lt;strong&amp;gt;Archimedes Inc.&amp;lt;/strong&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;div class="m-preview-list-sectors"&amp;gt;Healthcare&amp;lt;/div&amp;gt;
&amp;lt;div class="m-preview-list-desc"&amp;gt;Archimedes applies quantitative analysis to evidence from clinical trials, epidemiological studies, and other sources to create models that show healthcare decision makers how different options affect outcomes and costs.&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;div class="m-list-company-full"&amp;gt;
&amp;lt;div class="m-half"&amp;gt;
&amp;lt;h3&amp;gt;Company Information&amp;lt;/h3&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Year Founded:&amp;lt;/strong&amp;gt; 2006&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Location:&amp;lt;/strong&amp;gt; San Francisco, CA&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;FTE:&amp;lt;/strong&amp;gt; 50&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Type of Company:&amp;lt;/strong&amp;gt; Private&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Company Function:&amp;lt;/strong&amp;gt; Data management and analysis&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Category:&amp;lt;/strong&amp;gt; Healthcare&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Source of Revenue: &amp;lt;/strong&amp;gt;Software licensing&amp;lt;/p&amp;gt;
&amp;lt;br/&amp;gt;&amp;lt;a class="m-button" href="/Archimedes-Inc/"&amp;gt;Comment&amp;lt;/a&amp;gt;
&amp;lt;br/&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;div class="m-half"&amp;gt;
&amp;lt;h3&amp;gt;Description:&amp;lt;/h3&amp;gt;
&amp;lt;p&amp;gt;Archimedes is a healthcare modeling and analytics organization. With the Archimedes Model at its core, the company enables people to combine real-world healthcare data and simulation data to create compelling and actionable evidence used in individual healthcare decision making, as well as in populations, with applications in health and economic outcomes research, policy creation, and clinical trial design and operations.&amp;lt;/p&amp;gt;
&amp;lt;h3&amp;gt;Social Impact:&amp;lt;/h3&amp;gt;
&amp;lt;p&amp;gt;Archimedes solutions help make better decisions about health and healthcare, whether for individuals or populations.&amp;lt;/p&amp;gt;
&amp;lt;h3&amp;gt;Financial Info:&amp;lt;/h3&amp;gt;
&amp;lt;p&amp;gt;Not answered by company&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;div class="m-full datasets"&amp;gt;
&amp;lt;h3&amp;gt;Datasets&amp;lt;/h3&amp;gt;
&amp;lt;ul&amp;gt;&amp;lt;li&amp;gt;&amp;lt;a href="http://www.cdc.gov/nchs/nhanes.htm"&amp;gt;National Health and Nutrition Examination Survey (NHANES)&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;


&amp;lt;li&amp;gt;&amp;lt;a href="http://www.cdc.gov/nchs/ahcd.htm"&amp;gt;National Ambulatory Medical Care Survey (NAMCS)&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;


&amp;lt;li&amp;gt;&amp;lt;a href="http://www.cdc.gov/nchs/nhds.htm"&amp;gt;National Hospital Discharge Survey (NHDS)&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;


&amp;lt;li&amp;gt;&amp;lt;a href="http://www.cdc.gov/nchs/data_access/cmf.htm"&amp;gt;Compressed Mortality File (CMF)&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;


&amp;lt;/ul&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/li&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I do want to point out the dataset nodes in particular. Each company node lists
zero or more datasets, each with a URL and a title. Here is how you query them.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df &amp;lt;- data.frame(urls = unlist(xpathApply(preview.html[[1]], "div[@class=\"m-list-company-full\"]/div[@class=\"m-full datasets\"]/ul/li/a/@href"), 
    use.names = FALSE), titles = xpathSApply(preview.html[[1]], "div[@class=\"m-list-company-full\"]/div[@class=\"m-full datasets\"]/ul/li/a/text()", 
    xmlValue))
kable(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style="text-align: left"&gt;urls&lt;/th&gt;
      &lt;th style="text-align: left"&gt;titles&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;http://www.cdc.gov/nchs/nhanes.htm&lt;/td&gt;
      &lt;td style="text-align: left"&gt;National Health and Nutrition Examination Survey (NHANES)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;http://www.cdc.gov/nchs/ahcd.htm&lt;/td&gt;
      &lt;td style="text-align: left"&gt;National Ambulatory Medical Care Survey (NAMCS)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;http://www.cdc.gov/nchs/nhds.htm&lt;/td&gt;
      &lt;td style="text-align: left"&gt;National Hospital Discharge Survey (NHDS)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style="text-align: left"&gt;http://www.cdc.gov/nchs/data_access/cmf.htm&lt;/td&gt;
      &lt;td style="text-align: left"&gt;Compressed Mortality File (CMF)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id="candidates-html"&gt;candidates (HTML)&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.opendata500.com/candidates/"&gt;&lt;code&gt;candidates&lt;/code&gt;&lt;/a&gt; is another HTML page
containing a non-standard representation of a data table about companies.
You can select the companies with the following XPath.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[1] "//div[@class=\"m-candidates isotopes-container\"]/div"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This file contains 501 companies. To give you a feel
for the schema, the first company is represented like this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;div class="m-candidates-item  Finance--Investment  NY "&amp;gt;
&amp;lt;a href="/1099is"&amp;gt;&amp;lt;h3&amp;gt;&amp;lt;strong&amp;gt;1099.is&amp;lt;/strong&amp;gt;&amp;lt;/h3&amp;gt;&amp;lt;/a&amp;gt;
&amp;lt;p class="m-homepage-list-location"&amp;gt; New York&amp;lt;/p&amp;gt;
&amp;lt;em&amp;gt; Finance &amp;amp;amp; Investment&amp;lt;/em&amp;gt;
&amp;lt;p class="m-homepage-list-desc"&amp;gt;1099.is helps people navigate the confusing tax code that applies to the self-employed, providing advice from experts and people who have been through this before in transparent, clear, simple language.&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I’d say that this file contains seven fields. Four of them are direct
questionnaire questions.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;XPath within the company node&lt;/th&gt;
      &lt;th&gt;Questionnaire question or meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;a/h3/strong/text()&lt;/td&gt;
      &lt;td&gt;Name of your company&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;p[@class=”m-homepage-list-location”]/text()&lt;/td&gt;
      &lt;td&gt;In which city is this company located?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;em/text()&lt;/td&gt;
      &lt;td&gt;Which best describes the function of your company?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;p[@class=”m-homepage-list-desc”]/text()&lt;/td&gt;
      &lt;td&gt;As a summary, please provide a one sentence description of your company.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Three of them are not.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;XPath within the company node&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;contains(@class, “preview-company”)&lt;/td&gt;
      &lt;td&gt;Is the company part of the “Preview” companies?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;contains(@class, “survey-company”)&lt;/td&gt;
      &lt;td&gt;Did the company submit the questionnaire, or were its data collected by undocumented means?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;a/@href&lt;/td&gt;
      &lt;td&gt;Link to a page on the Open Data 500 site with more information from the questionnaire about the company&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id="loading-into-r"&gt;Loading into R&lt;/h2&gt;
&lt;p&gt;You can load the data into R like so.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;system('npm install r-open-data-500')
library(nprm)
open.data.500 &amp;lt;- nprm.require('open-data-500')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you haven’t installed &lt;a href="https://github.com/tlevine/nprm"&gt;nprm&lt;/a&gt;,
install it like so.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(devtools)
install_github('nprm','tlevine')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you don’t want to use nprm, you can manually download
&lt;a href="https://raw.github.com/tlevine/open-data-500/master/main.r"&gt;this script&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="distintion-between-the-preview-and-the-candidates"&gt;Distintion between the “Preview” and the “Candidates”&lt;/h2&gt;
&lt;p&gt;The Open Data 500 Team released an
“&lt;a href="http://www.opendata500.com/preview/"&gt;in-depth view&lt;/a&gt;” of “50 of the first
to complete [the] survey”. They also released a
“&lt;a href="http://www.opendata500.com/candidates/"&gt;full list&lt;/a&gt;” of
“500 candidate companies”.&lt;/p&gt;

&lt;p&gt;I explained earlier that some data were collected through a questionnaire
and that others were collected through an undocumented process. The “preview”
companies are the ones for which the data were collected by questionnaire;
the “candidates” include both these companies and the companies whose data
were collected by the undocumented means. Here’s how I figured that out.&lt;/p&gt;

&lt;h3 id="are-they-just-the-companies-that-have-submitted-questionnaires"&gt;Are they just the companies that have submitted questionnaires?&lt;/h3&gt;
&lt;p&gt;The preview companies are simply all of the companies that have
submitted the questionnaire; the non-preview companies are companies for
which the the Open Data 500 team effectively filled out the questionnaire.&lt;/p&gt;

&lt;p&gt;I came to that conclusion by looking at the following plot. In this plot,
the height of the bars represents the number of companies in a particular
category. The left category is companies that have completed the questionnaire,
and the right category is companies that haven’t. (The Open Data 500 Team
collect information about the companies but not through a questionnaire.)
The datasets are also color-coded based on whether the companies are included
in the Preview set.&lt;/p&gt;

&lt;p&gt;&lt;img src="figure/preview_v_candidates.png" alt="Preview companies are questionnaire responses" class="wide" /&gt;&lt;/p&gt;

&lt;p&gt;Note that the entire left bar is blue and the entire right bar is red;
this means that all of the survey companies are in the preview set and
that none of the non-survey companies are in the preview set.&lt;/p&gt;

&lt;p&gt;Well maybe. Given what I’m about to say in the next section, I’m starting
to wonder whether there was a mistake in the HTML version.&lt;/p&gt;

&lt;h2 id="which-companies-are-in-the-preview"&gt;Which companies are in the preview?&lt;/h2&gt;
&lt;p&gt;I still haven’t resolved which companies are considered to be the preview
companies.&lt;/p&gt;

&lt;h3 id="companies"&gt;51 companies?&lt;/h3&gt;
&lt;p&gt;Three of the files (&lt;code&gt;Preview50_Companies.csv&lt;/code&gt;, &lt;code&gt;OD500_Companies.json&lt;/code&gt;,
and &lt;code&gt;preview&lt;/code&gt;) agree as to which companies are in the preview.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;all(setequal(preview.companies.csv, preview.companies.json), setequal(preview.companies.csv, 
    preview.companies.preview.html))
## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;According to those three files, the following
51 companies are in the preview.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; [1] "Archimedes Inc."          "Azavea"                  
 [3] "BillGuard"                "BuildZoom"               
 [5] "Calcbench, Inc."          "Captricity"              
 [7] "Civinomics"               "Climate Corporation"     
 [9] "Construction Monitor LLC" "Consumer Reports"        
[11] "Energy Points, Inc."      "Energy Solutions Forum"  
[13] "Enigma.io"                "Esri"                    
[15] "FarmLogs"                 "Fastcase"                
[17] "GreatSchools"             "HDScores, Inc"           
[19] "Healthgrades"             "HealthPocket, Inc."      
[21] "HelloWallet"              "iTriage"                 
[23] "Lawdragon"                "LegiNation, Inc."        
[25] "Lucid"                    "MapBox"                  
[27] "Mercaris"                 "New Media Parents"       
[29] "Ontodia, Inc"             "OpportunitySpace, Inc."  
[31] "Overture Technologies"    "Owler"                   
[33] "Panjiva"                  "Personal, Inc."          
[35] "PolicyMap"                "Quertle"                 
[37] "Science Exchange"         "SeeClickFix"             
[39] "Simple Energy"            "Socrata"                 
[41] "SolarList"                "SpotCrime"               
[43] "Stormpulse"               "StreetCred Software, Inc"
[45] "Symcat"                   "Synthicity"              
[47] "TagniFi"                  "Trulia"                  
[49] "Walk Score"               "Way Better Patents"      
[51] "Brightscope"
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="companies-1"&gt;100 companies?&lt;/h3&gt;
&lt;p&gt;The remaining file, &lt;code&gt;candidates&lt;/code&gt;, agrees that the above companies are in
the preview,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;setequal(intersect(preview.companies.candidates.html, preview.companies.csv), 
    preview.companies.csv)
## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;but it includes 49  additional companies, for a total of 100.&lt;/p&gt;

&lt;h3 id="companies-2"&gt;50 companies?&lt;/h3&gt;
&lt;p&gt;There is even a third conflicting concept of the preview!
Several articles indicate that there are 50 companies in the preview,
not 51 nor 100.&lt;/p&gt;

&lt;p&gt;The introduction to the &lt;a href="http://www.opendata500.com/preview/"&gt;&lt;code&gt;preview&lt;/code&gt;&lt;/a&gt; page says
“[t]hese companies are 50 of the first to complete our survey for the Open Data 500”.
The &lt;a href="http://www.opendata500.com/download/"&gt;download&lt;/a&gt; page calls the preview
files “List[s] of 50”. The &lt;a href="http://www.opendata500.com/"&gt;home page&lt;/a&gt; says that the
preview is the “list of the first 50 companies that have filled out our survey”.&lt;/p&gt;

&lt;p&gt;The various press coverage also counts the preview companies at 50.
The article in
&lt;a href="http://www.forbes.com/sites/bethsimonenoveck/2014/01/08/from-faith-based-to-evidence-based-the-open-data-500-and-understanding-how-open-data-helps-the-american-economy/"&gt;Forbes&lt;/a&gt;
says “We’ve also posted in-depth profiles of 50 of them”.
The &lt;a href="http://www.informationweek.com/government/open-government/open-government-data-companies-cash-in/d/d-id/1113143"&gt;Information Week&lt;/a&gt; article
says that “[i]n addition to publishing a list of 500 open data companies,
GovLab also published profiles of 50 companies creating value from open government data.”
And the &lt;a href="http://fedscoop.com/open-data-500-intersection-open-data-economy/"&gt;Fedscoop&lt;/a&gt; article
talks about “50 companies profiled for early release”.&lt;/p&gt;

&lt;h2 id="which-companies-are-the-candidates"&gt;Which companies are the candidates?&lt;/h2&gt;
&lt;p&gt;There are also slight conflicts as to what the full list of companies is.&lt;/p&gt;

&lt;h3 id="what-the-data-files-say"&gt;What the data files say&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;500_Companies.csv&lt;/code&gt; contains 503 companies, and
&lt;code&gt;candidates&lt;/code&gt; contains 501 companies.
Collectively, they list 505 different
companies, and they agree about 498 of these 505 companies.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;csv &amp;lt;- cset(sub(" *$", "", candidates.csv$CompanyName))
html &amp;lt;- cset(sub(" *$", "", as.character(candidates.html$name)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These are in the CSV but not in the HTML.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(cset_difference(csv, html))
## {"Bureau Blank", "Capital Access Network", "DocGraph Journal",
##  "Opower", "Spikes Cavell"}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These are in the HTML but not in the CSV.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(cset_difference(html, csv))
## {"CAN Capital", "Roadify", "Spikes Cavell Analytic Inc"}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="what-the-descriptions-in-english-say"&gt;What the descriptions in English say&lt;/h3&gt;
&lt;p&gt;Much of the Open Data 500 website references a list of 500 companies.
The &lt;a href="http://www.opendata500.com/download"&gt;download page&lt;/a&gt; refers to
&lt;a href="http://www.opendata500.com/download/500_Companies.csv"&gt;&lt;code&gt;500_Companies.csv&lt;/code&gt;&lt;/a&gt;
as the “List of 500 Candidates”. And the three news articles linked from
the homepage also reference a list of 500 companies.&lt;/p&gt;

&lt;h2 id="ness"&gt;500-ness&lt;/h2&gt;
&lt;p&gt;I’m still unsure as to what the “500” in the title means.
As we saw above, it might have something to do with the number of responses,
but I find it odd that someone would name a study after its sample size.
So there’s probably more to it.&lt;/p&gt;

&lt;h3 id="fortune-500"&gt;Fortune 500?&lt;/h3&gt;
&lt;p&gt;Many people have suggested that the name is allusion to
&lt;a href="http://en.wikipedia.org/wiki/Fortune_500"&gt;Fortune 500&lt;/a&gt;,
but I don’t think that’s it.
The Fortune 500 is list of “the top 500 U.S. closely held and public
corporations as ranked by their gross revenue after adjustments”. That is,
it’s the 500 biggest U.S. companies for a particular definition of “big”.&lt;/p&gt;

&lt;p&gt;The Fortune 500 and the Open Data 500 are both about U.S. companies, but
the similarities stop there; as explained on the
“&lt;a href="http://www.opendata500.com/about/#about-results"&gt;About&lt;/a&gt;” page,
the Open Data 500 is explicitly not a ranking and not about company size.&lt;/p&gt;

&lt;h3 id="number-of-responses"&gt;Number of responses?&lt;/h3&gt;
&lt;p&gt;The website says that the Open Data 500 is a list of 500 companies, so it
might be that the “500” refers to the number of companies that they listed.
As I said above, naming studies after their sample size is a bit odd.
It seems like they continued looking for companies until they came up with
500, but I don’t understand why they chose the number 500.&lt;/p&gt;

&lt;p&gt;The Open Data 500 website &lt;a href="http://www.opendata500.com/about/#about-results"&gt;says&lt;/a&gt;
that “the Open Data 500 study is not meant to provide information for definitive
statistical analysis”, so I doubt they did anything like a power analysis to
determine how many they needed.&lt;/p&gt;

&lt;p&gt;One member of the Team told me that this was just a big number as a challenge
to themselves. Another told me that they expected, based on Joel Gurin’s
network, that there were about 500 companies that would respond.&lt;/p&gt;

&lt;h2 id="key-points-and-recommendations"&gt;Key points and recommendations&lt;/h2&gt;
&lt;p&gt;That was a lot of details of the Open Data 500 data. Let’s see if I can
summarize my conclusions about the structure of the study and the data.&lt;/p&gt;

&lt;h3 id="two-sub-studies"&gt;Two sub-studies&lt;/h3&gt;
&lt;p&gt;The Open Data 500 Team is assembling two lists.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The shorter list&lt;/strong&gt; (called the “preview” or the “list of 50”) is the
results of a questionnaire, with one response per company. This part is
a straightforward questionnaire-based case study, and the data that get
released come directly from the questionnaires.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The longer list&lt;/strong&gt; (called the “list of 500 candidates”) makes more sense
if you think about it as the sum of two lists; some of the companies come from
the shorter list (the questionnaire responses), and the rest (most) come from
an undocumented process.&lt;/p&gt;

&lt;h3 id="which-data-files-you-should-use"&gt;Which data files you should use&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;If you are interested in the questionnaire results&lt;/strong&gt;, I recommend using the
&lt;a href="http://www.opendata500.com/download/Preview50_Companies.csv"&gt;&lt;code&gt;Preview50_Companies.csv&lt;/code&gt;&lt;/a&gt;
file; this file is structured more simply than the corresponding JSON files
(&lt;a href="http://www.opendata500.com/download/OD500_Companies.json"&gt;&lt;code&gt;OD500_Companies.json&lt;/code&gt;&lt;/a&gt;
and &lt;a href="http://www.opendata500.com/download/OD500_Datasets.json"&gt;&lt;code&gt;OD500_Datasets.json&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you are interested in the long list&lt;/strong&gt;, choose your data file based on the
fields you want and based on whether you want the full list or an incomplete list.
The two files contain different columns; for example, the flag as to whether the
data come from the questionnaire or the undocumented process is only available
in the HTML version,
and the link to the company website is only available in the CSV version.
Thus, you need to choose the file based on which fields you need.
Also, each of these files contains different companies; if you want to have the
full list of companies, you need to combine these files, removing duplicates.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;I’ve already loaded the data into R&lt;/strong&gt;, so look
&lt;a href="#loading-into-r"&gt;here&lt;/a&gt; if you want that.&lt;/p&gt;

&lt;h3 id="other-confusing-things"&gt;Other confusing things&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;The “500” in “Open Data 500” doesn’t mean anything&lt;/strong&gt; as far as I can tell;
it’s not the number of responses, and it’s not a reference to the Fortune 500.
Don’t let this confuse you.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Open Data 500 is considered “comprehensive” because of its sampling strategy&lt;/strong&gt;,
which is termed “comprehensive call”. This strategy is a form of convenience sampling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Open Data 500 is only at data collection stage&lt;/strong&gt;; the “analysis”
component of the study has yet to begin. But the data are already being
released, so you can start analyzing the data before the Open Data 500
Team does!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The different data files present conflicting versions of the data&lt;/strong&gt;,
and I haven’t figured out how to resolve this.
The different data files do largely agree with each other,
so any one should be okay for prototyping your analyses. You should contact the
Open Data 500 Team for clarification when this starts to matter.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:www.thomaslevine.com,2014-01-27:/!/better-datasets-about-open-data/index.html</id>
    <title type="html">Organizing my data about data</title>
    <published>2014-01-27T00:00:00Z</published>
    <updated>2014-01-27T00:00:00Z</updated>
    <link rel="alternate" href="http://www.thomaslevine.com/!/better-datasets-about-open-data/index.html"/>
    <content type="html">&lt;p&gt;I’ve recently been &lt;a href="/open-data"&gt;studying data about open data&lt;/a&gt;,
and I want to make it easy for other people to use my data data for more
data data studies.
I previously &lt;a href="/!/my-datasets-about-open-data"&gt;documented&lt;/a&gt;
much of the data data that I’d collected, but that was all a mess,
so I’ve been organizing them a bit more nicely. All of the old stuff
still applies, but stuff I do in the near future will follow the
presently document structure.&lt;/p&gt;

&lt;h2 id="getting-the-code"&gt;Getting the code&lt;/h2&gt;
&lt;p&gt;I’m trying to put all programs for accessing the data data into a single git
repository &lt;a href="https://github.com/tlevine/open-data"&gt;hosted on GitHub&lt;/a&gt;.
Get it like so.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone git@github.com:tlevine/open-data.git --recursive
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You need &lt;code&gt;--recursive&lt;/code&gt; because
there are separate submodules for different data data sources.&lt;/p&gt;

&lt;h2 id="running-things"&gt;Running things&lt;/h2&gt;
&lt;p&gt;Most of the directions for downloading stuff from other places are written as
Python modules and are stored in the root of the repository. I intend for
&lt;code&gt;run.py&lt;/code&gt; to be the entry point to all of these modules. In some cases,
however, I copied a file from another place and didn’t integrate it into this
structure.&lt;/p&gt;

&lt;p&gt;Don’t expect things to be particularly well documented, but you can try to
figure out what I did by looking in the Makefile.
Most of the make tasks involve importing the &lt;code&gt;run.py&lt;/code&gt; file and
running one of the functions in it.&lt;/p&gt;

&lt;h2 id="directory-structure"&gt;Directory structure&lt;/h2&gt;
&lt;p&gt;The root of the repository contains five directories.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git ls-files|sed -n 's/\/.*//p'|uniq
downloads
instances.ckan.org
opendata.socrata.com
reports
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;instances.ckan.org&lt;/code&gt; and &lt;code&gt;opendata.socrata.com&lt;/code&gt; directories contain one
webpage file each. These files contain lists of data catalogs.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;downloads&lt;/code&gt; directory contains a few git submodules, and most of the 
stuff that gets downloaded winds up in these submodules.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;reports&lt;/code&gt; directory contains lots of English and R rather than Python.
Each report has an R script (named something &lt;code&gt;.r&lt;/code&gt;) that renders an Rmarkdown
file (named something &lt;code&gt;.Rmd&lt;/code&gt;). There are other small files too, but I don’t
have a system as to why they go where they do.&lt;/p&gt;

&lt;p&gt;Some of the scripts produce a &lt;code&gt;./cache&lt;/code&gt; directory.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls -d */
cache/  downloads/  instances.ckan.org/  opendata.socrata.com/  reports/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The function of this directory is explained later.&lt;/p&gt;

&lt;h2 id="loading-cached-data"&gt;Loading cached data&lt;/h2&gt;
&lt;p&gt;On all of the computers that I might run this code on, I store the &lt;code&gt;/tmp&lt;/code&gt; 
directory on RAM.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ df -h|sed -n -e 1p -e '/\/tmp$/p'
Filesystem      Size  Used Avail Use% Mounted on
tmpfs           7.8G  1.3G  6.6G  16% /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make things run faster, I use &lt;code&gt;/tmp/open-data.sqlite&lt;/code&gt; to store caches that
I can lose. Run &lt;code&gt;make to-disk&lt;/code&gt; to copy this file to the &lt;code&gt;./cache&lt;/code&gt; directory, 
and run &lt;code&gt;make from-disk&lt;/code&gt; to copy &lt;code&gt;./cache/open-data.sqlite&lt;/code&gt; to the &lt;code&gt;/tmp&lt;/code&gt; directory.&lt;/p&gt;

&lt;h2 id="documentation"&gt;Documentation&lt;/h2&gt;
&lt;p&gt;If it’s taking you a while to figure out how something works,
&lt;a href="&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#095;&amp;#064;&amp;#116;&amp;#104;&amp;#111;&amp;#109;&amp;#097;&amp;#115;&amp;#108;&amp;#101;&amp;#118;&amp;#105;&amp;#110;&amp;#101;&amp;#046;&amp;#099;&amp;#111;&amp;#109;"&gt;email me&lt;/a&gt;, and I might document it.
And if you figure out how something works, do send me any
documentation that you happen to come up with, even if it’s a mess.&lt;/p&gt;
</content>
  </entry>
</feed>

